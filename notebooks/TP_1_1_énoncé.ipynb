{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Avant de débuter ce TP** :\n",
    "\n",
    "1. **Changez le type d'exécution sur Google Colab** : `Exécution > Modifiez le type d'exécution > T4 GPU`\n",
    "2. **Installez les paquets ci-dessous** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install lightning torchmetrics torchinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apprentissage profond - TP 1.1\n",
    "\n",
    "Il existe de nombreuses bibliothèques et langages de programmation pour pratiquer de l'apprentissage profond. Au cours de ces travaux pratiques, nous utiliserons le langage de programmation Python, ainsi que le paquet [PyTorch](https://pytorch.org) et d'autres paquets de cet écosystème.\n",
    "\n",
    "L'objectif de ce Jupyter notebook est de vous fournir les bases pour débuter avec la bibliothèque Pytorch. À la fin de ce notebook, vous devez être capables de :\n",
    "* **travailler avec des tenseurs**,\n",
    "* **indiquer comment accéder aux données pour entraîner et évaluer un modèle**,\n",
    "* **construire un réseau de neurones artificiels**, et\n",
    "* **entraîner et évaluer votre modèle**.\n",
    "\n",
    "Le contenu de ce notebook est basé sur les [tutoriels](https://pytorch.org/tutorials/) disponibles sur le site de Pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tenseurs\n",
    "\n",
    "Les tenseurs PyTorch suivent une structure de données spécialisée et sont très similaires aux tableaux NumPy. Les tenseurs sont utilisés pour modéliser les entrées et les sorties d'un modèle, ainsi que les paramètres du modèle.\n",
    "\n",
    "Les tenseurs PyTorch sont similaires aux tableaux NumPy, une différence majeure étant que les tenseurs peuvent être exécutés sur des cartes graphiques (*graphical processing units* ou GPUs).\n",
    "En fait, les tenseurs PyTorch et les tableaux NumPy peuvent même partager le même espace mémoire, d'où l'absence de devoir copier les données.\n",
    "Les tenseurs sont également optimisés pour la [dérivation automatique](https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html).\n",
    "Si vous êtes familiers avec les tableaux NumPy, vous le serez rapidement également avec les tenseurs PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialiser un tenseur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directement à partir de données \"Python\"\n",
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# À partir d'un tableau NumPy\n",
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "x_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# À partir d'un autre tenseur\n",
    "x_ones = torch.ones_like(x_data)\n",
    "x_ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avec des valeurs aléatoires ou une seule et unique valeur\n",
    "shape = (2, 3)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Tenseur aléatoire : \\n {rand_tensor} \\n\")\n",
    "print(f\"Tenseur avec que des uns: \\n {ones_tensor} \\n\")\n",
    "print(f\"Tenseur avec que des zéros : \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributs d'un tenseur\n",
    "\n",
    "Les attributs d'un tenseur décrivent ses caractéristiques telles que sa forme, son type de données ou encore sur quel type d'appareil il est sauvegardé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Forme du tenseur : {tensor.shape}\")\n",
    "print(f\"Type de données du tenseur : {tensor.dtype}\")\n",
    "print(f\"Appareil sur lequel le tenseur est sauvegardé : {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**À noter que le type de données par défaut d'un tenseur est `float32`, alors que le type par défaut d'un tableau NumPy est `float64`. PyTorch impose que tous les tenseurs aient le même type de données pour effectuer des opérations entre eux.**\n",
    "\n",
    "Vous pouvez changer le type de données d'un tenseur avec la méthode `to()` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_np.to(dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opérations sur des tenseurs\n",
    "\n",
    "De nombreuses opérations, telles que l'arithmétique, l'algèbre linéaire et des opérations matricielles (telles que la transposée, l'indexation ou encore les coupes) sont détaillées dans la [documentation](https://pytorch.org/docs/stable/torch.html).\n",
    "\n",
    "Chacune de ces opérations peut être exécutée sur GPU (en général plus rapidement que sur CPU).\n",
    "Sur Google Colab, changez le type d'exécution (CPU ou GPU) relance le noyau, c'est-à-dire qu'il faut exécuter à nouveau tout le code précédemment exécuté.\n",
    "**C'est pourquoi la première instruction de ce notebook, ainsi que de de tous les autres notebooks, est de changer le type d'exécution et de choisir GPU au lieu de CPU.**\n",
    "Les TPUs (pour [*Tensor Processing Units*](https://en.wikipedia.org/wiki/Tensor_Processing_Unit)) sont d'autres accélérateurs matériels, développés par Google, mais nous ne les utiliserons pas. \n",
    "\n",
    "Par défaut, les tenseurs sont créés sur le CPU. Il faut explicitement déplacer les tenseurs sur le GPU en utilisant la méthode `to()` (après avoir vérifié la disponibilité de GPUs). Gardez en tête que copier de grands tenseurs sur d'autres appareils peut être coûteux à la fois en terme de temps et de mémoire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple : déplacer un tenseur sur un GPU s'il y en a un de disponible\n",
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opérations d'indexation et de coupes (similaires aux tableaux NumPy)\n",
    "tensor = torch.ones(4, 4)\n",
    "print(f\"Première ligne : {tensor[0]}\")\n",
    "print(f\"Première colonne : {tensor[:, 0]}\")\n",
    "print(f\"Dernière colonne : {tensor[..., -1]}\")\n",
    "tensor[:, 1] = 0  # Modification de la deuxième colonne\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenation de tenseurs (le long d'une dimension donnée)\n",
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opérations arithmétiques\n",
    "\n",
    "## Trois manières d'effectuer la multiplication matricielle\n",
    "y1 = tensor @ tensor.T\n",
    "\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "y3 = torch.rand_like(y1)\n",
    "torch.matmul(tensor, tensor.T, out=y3)\n",
    "\n",
    "## Trois manières d'effectuer la multiplication élément par élément\n",
    "z1 = tensor * tensor\n",
    "\n",
    "z2 = tensor.mul(tensor)\n",
    "\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor, out=z3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tenseur à un seul élément et récupération de la valeur en un type natif de Python.\n",
    "agg = tensor.sum()\n",
    "print(agg, type(agg))\n",
    "\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jeu de données et chargeurs de données\n",
    "\n",
    "L'accès aux données est un élément essentiel pour pouvoir entraîner des modèles. PyTorch met à disposition deux outils qui permettent de faciliter l'accès aux données : [torch.utils.data.Dataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) et [torch.utils.data.DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader). Ces outils permettent de travailler à la fois sur des jeux de données publics et très couramment utilisés, mais aussi sur son propre de jeu de données.\n",
    "\n",
    "La classe [torch.utils.data.Dataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) permet de définir un jeu de données, notamment sa taille (c'est-à-dire son nombre d'observations) et comment accéder à n'importe quelle observation.\n",
    "\n",
    "La classe [torch.utils.data.DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) permet de définir, pour un jeu de données, un chargeur de données, notamment comment accéder à plusieurs observations à la fois, s'il faut mélanger ou non l'ordre des observations, etc. Le chargeur de données est l'outil utilisé pour l'entraînement et l'évaluation des modèles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement d'un jeu de données couramment utilisé\n",
    "\n",
    "Certains jeux de données couramment utilisés peuvent être facilement téléchargés grâce à des outils fournis dans d'autres bibliothèques de l'écosystème PyTorch telles que [TorchVision](https://pytorch.org/vision/stable/index.html), [TorchText](https://pytorch.org/text/stable/index.html) et [TorchAudio](https://pytorch.org/audio/stable/index.html).\n",
    "\n",
    "Dans ce tutoriel, nous allons télécharger et utiliser le jeu de données [Fashion MNIST](https://en.wikipedia.org/wiki/Fashion_MNIST), consistué d'images de mode de taille `28 x 28`. Le jeu d'entraînement est composé de 60 000 images, tandis que le jeu d'évaluation est composé de 10 000 images. Le jeu de données est disponible via la classe [torchvision.datasets.FashionMNIST](https://pytorch.org/vision/stable/generated/torchvision.datasets.FashionMNIST.html#torchvision.datasets.FashionMNIST)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "\n",
    "dataset_train = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "dataset_val = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Itération et visualisation du jeu de données\n",
    "\n",
    "Une instance de la classe `Dataset` est indexable, comme une liste Python : `training_data[index]`.\n",
    "\n",
    "Comme nos observations sont des images, nous allons visualiser certaines observations à l'aide de la bibliothèque `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "\n",
    "\n",
    "# Affichage de 9 observations du jeu d'entraînement choisies aléatoirement\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(dataset_train), size=(1,)).item()\n",
    "    img, label = dataset_train[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Travailler avec son propre jeu de données\n",
    "\n",
    "En pratique, vous ne travaillerez pas sur un jeu de données public couramment utilisé mais sur votre propre jeu de données. Il reste néanmoins possible d'utiliser certains outils mis à disposition, à condition de respecter certaines contraintes.\n",
    "\n",
    "Si vous travaillez sur votre propre jeu de données, il va falloir définir une classe héritant de la classe `torch.utils.data.Dataset` qui définit les trois méthodes suivantes :\n",
    "* `__len__()` : cette méthode renvoie le nombre d'observations du jeu de données.\n",
    "* `__getitem__()` : cette méthode charge et renvoie la n-ième observation du jeu de données (où n est un argument de la méthode)\n",
    "* `__init__()` : cette méthode définit toutes les informations nécessaires pour l'implémentation des deux autres méthodes.\n",
    "\n",
    "Vous trouverez [ici](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#creating-a-custom-dataset-for-your-files) un exemple tiré de la documentation de PyTorch pour un jeu de données constitué d'images. Cet exemple est copié-collé ci-dessous. **Ce n'est qu'un exemple, il ne faut pas le copier-coller sans le comprendre.**\n",
    "\n",
    "\n",
    "```python\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparer les données pour l'entraînement avec le DataLoader\n",
    "\n",
    "La classe `Dataset` permet de récupérer n'importe quelle observation d'un jeu de données. Lors de l'entraînement d'un modèle, on veut en général accéder à plusieurs observations à la fois (en mini-lots) et mélanger le jeu de données à chaque époque pour réduire le surapprentissage.\n",
    "\n",
    "Pour ce faire, on utilise la classe [torch.utils.data.Dataloader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader). Son premier argument, obligatoire, est le jeu de données, c'est-à-dire l'instance de la classe [torch.utils.data.Dataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset).\n",
    "Les autres arguments importants, optionnels, sont la taille du lot (`batch_size`) et le fait de mélanger ou non le jeu de données (`shuffle`). Mélanger le jeu de données pendant l'entraînement peut être utile pour éviter le surapprentissage, mais c'est inutile pour l'évaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=100, shuffle=True)\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Itération à travers le `DataLoader`\n",
    "\n",
    "On a chargé le jeu de données et on peut itérer à travers le jeu de données. En utilisant les fonctions natives [iter()](https://docs.python.org/fr/3/library/functions.html#iter) et [next()](https://docs.python.org/fr/3/library/functions.html#next), on peut accéder au prochain lot d'observations :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get the next mini-batch of samples\n",
    "train_features, train_labels = next(iter(dataloader_train))\n",
    "print(f\"Taille du tenseur contenant les images du lot d'observations : {train_features.size()}\")\n",
    "print(f\"Taille du tenseur contenant les labels du lot d'observations : {train_labels.size()}\")\n",
    "\n",
    "# Display the image and the label of the first sample in the mini-batch\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.title(f\"Classe : {labels_map[label.item()]}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construire, entraîner et évaluer un réseau de neurones artificiels avec PyTorch\n",
    "\n",
    "### Construction d'un réseau de neurones avec PyTorch\n",
    "\n",
    "Pour construire un réseau de neurones avec PyTorch, il y a quelques règles simples à respecter :\n",
    "* Il faut définir une classe héritant de la classe [torch.nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html).\n",
    "* La classe doit contenir au moins les deux méthodes suivantes :\n",
    "    + Le constructeur `__init__()`, où on appelle toujours le constructeur de la classe mère et où on initialise toutes les couches (et où on peut également définir les fonctions d'activation).\n",
    "    + La méthode `forward()` qui définit la passe avant, c'est-à-dire comment passer de l'entrée à la sortie.\n",
    "\n",
    "Tous les éléments nécessaires pour définir un réseau de neurones se trouvent dans le module [torch.nn](https://pytorch.org/docs/stable/nn.html), en particulier toutes les couches et fonctions d'activation.\n",
    "\n",
    "Dans l'exemple ci-dessous, on définit un réseau de neurones avec l'architecture séquentielle suivante :\n",
    "1. une couche d'aplatissement, pour transformer une image en un vecteur,\n",
    "2. une première couche linéaire avec $28 \\times 28 = 784$ entrées et $512$ sorties,\n",
    "3. la fonction d'activation ReLU,\n",
    "4. une deuxième couche linéaire avec $512$ entrées et $512$ sorties,\n",
    "5. la fonction d'activation ReLU,\n",
    "6. une troisième couche linéaire avec $512$ entrées et $10$ sorties.\n",
    "\n",
    "Vous remarquerez qu'on n'utilise pas la fonction d'activation $\\text{softmax}$ pour transformer le dernier vecteur de 10 réels en un vecteur de probabilités. En effet, la fonction $\\text{softmax}$ utilise la fonction exponentielle et la fonction de coût que nous allons utiliser, l'entropie croisée, utilise le logarithme des probabilités. Il est donc plus simple (et c'est également numériquement plus stable) de travailler directement avec les **logits** plutôt que les probabilités."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetworkPyTorch(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        # On appelle toujours le constructeur de la classe mère\n",
    "        super().__init__()\n",
    "        \n",
    "        # Convertit un tenseur multidimensionnel en un tenseur unidimensionnel\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        \n",
    "        # Première couche linéaire\n",
    "        self.linear1 = torch.nn.Linear(28 * 28, 512)\n",
    "        \n",
    "        # Première fonction d'activation\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        \n",
    "        # Deuxième couche linéaire\n",
    "        self.linear2 = torch.nn.Linear(512, 512)\n",
    "        \n",
    "        # Deuxième fonction d'activation\n",
    "        self.relu2 = torch.nn.ReLU()\n",
    "\n",
    "        # Troisième couche linéaire\n",
    "        self.linear3 = torch.nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.flatten(x)\n",
    "        y = self.linear1(y)\n",
    "        y = self.relu1(y)\n",
    "        y = self.linear2(y)\n",
    "        y = self.relu2(y)\n",
    "        y = self.linear3(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un inconvénient évident de l'approche est qu'on est obligés d'appeler chaque couche et chaque fonction d'activation une par une. C'est non seulement énervant même pour une architecture aussi petite, mais c'est en plus un risque d'erreur non négligeable, surtout avec un réseau plus grand. Heureusement, dans le cas où une partie de l'architecture est séquentielle, on peut utiliser la classe [torch.nn.Sequential()]() pour indiquer la liste des couches et fonctions d'activation de la séquence. Quand on appele ensuite cet objet, la séquence est parcourue dans l'ordre fourni et on récupère simplement la sortie de la séquence.\n",
    "\n",
    "Le code ci-dessous illustre la simplification de la méthode `forward()` en utilisant cet outil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetworkPyTorchSimpler(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.sequential = torch.nn.Sequential(\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(28 * 28, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sequential(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut visualiser l'architecture de notre réseau de neurones en utilisant la fonction [torchinfo.summary()](https://github.com/TylerYep/torchinfo?tab=readme-ov-file#documentation). En lui fournissant également la taille de l'entrée (en incluant la dimension pour le lot), on peut facilement visualiser la taille de la sortie de chaque couche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "model = NeuralNetworkPyTorchSimpler()\n",
    "summary(model, input_size=(64, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appareil (*device*) sur lequel travailler\n",
    "\n",
    "Par défaut, tous les tenseurs définis sont mis sur les **unités centrales de traitement** (CPU pour *central processing units* en anglais). Cependant, il existe d'autres unités, telles que les **unités de traitement graphique** (GPU pour *graphical processing units* en anglais), qui sont bien plus rapides pour effectuer certaines opérations mathématiques, notamment celles nécessaires en apprentissage profond telles que le calcul matriciel.\n",
    "\n",
    "**En gros, si vous utilisez des GPUs au lieu de CPUs, l'exécution des passes avant et arrière sera, *en général*, bien plus rapide : l'entraînement et l'inférence seront donc, *en général*, bien plus rapides.**\n",
    "\n",
    "Sur Google Colab, vous pouvez modifier les ressources auxquelles vous avez accès en allant dans `Exécution > Modifier le type d'exécution` et en cliquant sur `T4 GPU` au lieu de `CPU`.\n",
    "Modifier l'accélérateur matériel redémarre votre noyau (c'est-à-dire que vous perdez toutes les variables que aviez définies et qu'il faut rexécuter le code depuis le début).\n",
    "**Il est donc important de choisir le type d'accélérateur matériel au tout début afin de ne pas perdre le travail déjà effectué.**\n",
    "\n",
    "**CUDA** (pour *Compute Unified Device Architecture*) est une technologie permettant d'exécuter des calculs sur un GPU à la place d'un CPU.\n",
    "C'est ce terme qui est utilisé dans la bibliothèque PyTorch.\n",
    "Pour savour (ou vérifier) si vous avez accès à un GPU, on utilise la fonction [torch.cuda.is_available()](https://pytorch.org/docs/stable/generated/torch.cuda.is_available.html) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Il est nécessaire de tout mettre sur le même appareil**. Par exemple, si on souhaite utiliser un GPU, alors il faut mettre le modèle sur le GPU mais aussi chaque lot d'observations sur le GPU pendant l'entraînement et l'inférence. On commence donc par mettre le modèle sur le GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pour effectuer la passe avant du modèle, on n'utilise pas directement pas la méthode `forward()` mais on appelle directement le modèle** (appeler le modèle effectue des opérations supplémentaires).\n",
    "Par exemple, avec le code ci-dessous :\n",
    "1. On définit ci-dessous une image où tous les pixels sont aléatoires et on la met sur le bon appareil.\n",
    "2. On effectue la passe avant pour obtenir les logits.\n",
    "3. On obtient l'indice de la classe prédite qui correspond à l'indice du logit maximal.\n",
    "4. On affiche le nom de la classe prédite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(X)\n",
    "y_pred = logits.argmax(1)\n",
    "print(f\"Classe prédite : {labels_map[y_pred.item()]}\")\n",
    "del X, logits, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entraînement et évaluation\n",
    "\n",
    "En utilisant uniquement le paquet PyTorch, il est nécessaire d'écrire soi-même le code pour l'entraînement et l'évaluation d'un modèle. Néanmoins, on a déjà défini presque tous les éléments nécessaires pour l'entraînement du modèle. Il nous reste à définir la fonction de coût, l'algorithme d'optimisation ainsi que certains hyperparamètres tels que le nombre d'époques.\n",
    "\n",
    "Le module [torch.nn](https://pytorch.org/docs/stable/nn.html) met à disposition les différentes [fonctions de perte](https://pytorch.org/docs/stable/nn.html#loss-functions) déjà implémentées dans PyTorch. Pour les algorithmes d'optimisation, il faut utiliser le module [torch.optim](https://pytorch.org/docs/stable/optim.html).\n",
    "\n",
    "* **Fonction de coût** : comme nous travaillons sur un problème de classification en classes multiples, nous allons utiliser l'*entropie croisée* : [torch.nn.CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html).\n",
    "* **Algorithme d'optimisation** : nous allons utiliser l'algorithme *Adam*, qui est en général un bon algorithme par défaut : [torch.optim.Adam](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html).\n",
    "\n",
    "À noter qu'on a déjà définit des hyperparamètres sans forcément s'en rendre compte, par exemple **la taille des lots** (`batch_size`) sur le jeu d'entraînement à travers le *dataloader* pour ce jeu. On utilise ici également les valeurs par défaut des hyperparamètres pour l'algorithme Adam, mais on pourrait les changer.\n",
    "\n",
    "En utilisant un nombre d'époques fixe, la procédure générale d'entraînement d'un modèle est la suivante :\n",
    "```\n",
    "Pour chaque époque\n",
    "    Pour chaque lot du jeu d'entraînement\n",
    "        [Optionnel] Mettre les données sur le bon appareil (GPU)\n",
    "        Effectuer la passe avant et calculer la fonction de coût\n",
    "        Effectuer la passe arrière (calculer les gradients)\n",
    "        Effectuer une étape d'optimisation (misee à jour des paramètres entraînables du modèle)\n",
    "```\n",
    "\n",
    "L'optimisation se déroule dans trois étapes de la boucle imbriquée :\n",
    "* La méthode `zero_grad()` de l'algorithme d'optimisation permet de réinitialiser les gradients des paramètres du modèle. Par défaut, les gradients s'accumulent au fil des itérations. Pour éviter cette accumulation, il faut explicitement les réinitialiser à zéro au début de chaque itération.\n",
    "* La passe arrière s'effectue grâce à la méthode `backward()` de la fonction de perte. Ici, PyTorch calcule le gradient de la fonction de coût par rapport à chaque paramètre entraînable.\n",
    "* La mise à jour des paramètres entraînables du modèle s'effectue grâce à la méthode `step()` de l'algorithme d'optimisation, à partir des gradients calculés durant la passe arrière.\n",
    "\n",
    "Le code ci-dessous définit trois fonctions :\n",
    "* La fonction `train_loop()` correspond à l'entraînement du modèle pendant une époque sur le jeu d'entraînement.\n",
    "* La fonction `eval_loop()` correspond à l'évaluation d'un modèle sur un jeu de données.\n",
    "* La fonction `train()` effectue l'entraînement complet du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_function, optimizer, device, verbose=False):\n",
    "    # Met le modèle en mode entraînement.\n",
    "    # C'est une bonne pratique à avoir car certaines couches ne se comportent\n",
    "    # pas de la même manière durant l'entraînement et l'inférence.\n",
    "    # Ici, cela n'a aucun impact car toutes les couches se comportent de la même manière.\n",
    "    model.train()\n",
    "\n",
    "    loss_mean, accuracy_mean = 0.0, 0.0\n",
    "\n",
    "    # Pour chaque lot\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "\n",
    "        # Réinitialise les gradients à zéro\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Met le lot d'observations sur le bon appareil\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # Effectue la passe avant et calcule la fonction de coût\n",
    "        pred = model(X)\n",
    "        loss = loss_function(pred, y)\n",
    "        accuracy = (pred.argmax(1) == y).to(torch.float).mean().item()\n",
    "\n",
    "        loss_mean += loss.item()\n",
    "        accuracy_mean += accuracy\n",
    "\n",
    "        # Effectue la passe arrière et met à jour les paramètres du modèle\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Affiche la valeur de la fonction de coût pour certains lots\n",
    "        if verbose and (batch % (len(dataloader) // 10) == 0):\n",
    "            loss = loss.item()\n",
    "            print(\n",
    "                f\"Fonction de coût = {loss: >7f} ; \"\n",
    "                f\"Précision = {accuracy:06.2%} \"\n",
    "                f\"[{batch: >3d} / {len(dataloader): >3d}]\"\n",
    "            )\n",
    "\n",
    "    loss_mean /= len(dataloader)\n",
    "    accuracy_mean /= len(dataloader)\n",
    "    \n",
    "    return loss_mean, accuracy_mean\n",
    "\n",
    "\n",
    "def eval_loop(dataloader, model, loss_function, device):\n",
    "\n",
    "    # Met le modèle en mode évaluation.\n",
    "    # C'est une bonne pratique à avoir car certaines couches ne se comportent\n",
    "    # pas de la même manière durant l'entraînement et l'inférence.\n",
    "    # Ici, cela n'a aucun impact car toutes les couches se comportent de la même manière.\n",
    "    model.eval()\n",
    "    \n",
    "    # Définit des variables nécessaires pour l'évaluation du modèle\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    loss, correct = 0.0, 0.0\n",
    "\n",
    "    # Évaluer le modèle dans un contexte `with torch.no_grad()` assure qu'aucun gradient\n",
    "    # n'est calculé pendant l'évaluation, ce qui évite des calculs inutiles.\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # Pour chaque lot\n",
    "        for X, y in dataloader:\n",
    "            \n",
    "            # Met le lot d'observations sur le bon appareil\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            # Effectue la passe avant\n",
    "            pred = model(X)\n",
    "            \n",
    "            # Calcule la fonction de coût et le nombre de bonnes prédictions\n",
    "            loss += loss_function(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    # Calcule la fonction de coût moyenne et la proportion de bonnes prédictions\n",
    "    loss /= num_batches\n",
    "    correct /= size\n",
    "    return loss, correct\n",
    "\n",
    "\n",
    "def train(model, dataloader_train, dataloader_val, loss_function, optimizer, n_epochs, device, verbose=True):\n",
    "    for epoch in range(n_epochs):\n",
    "        string = f\"Époque {epoch + 1:{len(str(n_epochs))}d} / {n_epochs}\"\n",
    "        print(f\"{string}\\n{'-' * len(string)}\")\n",
    "        print(\" Jeu d'entraînement \".center(54 + 2 * len(str(len(dataloader_train))) , '#'))\n",
    "\n",
    "        # Training loop\n",
    "        loss_train, accuracy_train = train_loop(\n",
    "            dataloader_train, model, loss_function, optimizer, device, verbose\n",
    "        )\n",
    "        print(f\"Fonction de coût = {loss_train: >7f} ; Précision = {accuracy_train:06.2%} [Moyenne]\")\n",
    "\n",
    "        # Evaluation loop\n",
    "        loss_val, accuracy_val = eval_loop(dataloader_val, model, loss_function, device)\n",
    "        print(\" Jeu de validation \".center(54 + 2 * len(str(len(dataloader_train))), '#'))\n",
    "        print(f\"Fonction de coût = {loss_val: >8f} ; Précision = {(accuracy_val):06.2%}\\n\")\n",
    "              \n",
    "\n",
    "    print(\"Entraînement terminé !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise la fonction `train()` pour entraîner le modèle pendant 5 époques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(\n",
    "    model=model,\n",
    "    dataloader_train=dataloader_train,\n",
    "    dataloader_val=dataloader_val,\n",
    "    loss_function=torch.nn.CrossEntropyLoss(),\n",
    "    optimizer=torch.optim.Adam(model.parameters()),\n",
    "    n_epochs=5,\n",
    "    device=device,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme vous pouvez le constater, entraîner un modèle avec PyTorch nécessite d'écrire pas mal de code.\n",
    "Néanmoins, on se rend compte que l'on écrit très souvent des bouts de code quasiment identiques sur différents projets, surtout lorsqu'on effectue des choses classiques.\n",
    "On va donc voir une autre bibliothèque qui va nous permettre de ne pas réécrire toujours le même code à chaque fois."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construire, entraîner et évaluer un réseau de neurones artificiels avec PyTorch Lightning\n",
    "\n",
    "### Les bases\n",
    "\n",
    "Une caractéristique de PyTorch est qu'il s'agit d'une bibliothèque relativement *low-level* : certaines fonctionnalités doivent être implémentées par l'utilisateur à partir des outils mis à disposition. Par exemple, pour l'entraînement, il faut à chaque fois écrire le code complet de la procédure.\n",
    "À l'inverse, dans des bibliothèques comme [scikit-learn](https://scikit-learn.org) en Python ou [caret](https://cran.r-project.org/web/packages/caret/index.html) en R, vous n'avez besoin que d'appeler la méthode `.fit()` ou la fonction `train()` pour effectuer l'entraînement.\n",
    "Certains hyperparamètres vous permettent d'effectuer des modifications sur comment est entraîné le modèle, mais vous n'avez pas à implémenter vous-même l'entraînement.\n",
    "\n",
    "Cet aspect *low-level* de PyTorch peut être pratique pour des travaux de recherche parce qu'on souhaite en général avoir accès à toutes les fonctionnalités pour pouvoir effectuer des modifications si nécessaires.\n",
    "Cela l'est moins quand on veut juste utiliser une version classique de l'entraînement.\n",
    "\n",
    "Pour ce faire, nous allons également utiliser une autre bilbiothèque Python appelée [PyTorch Lightning](https://lightning.ai/pytorch-lightning), qui va nous permettre d'éviter d'écrire une partie du code pour l'entraînement et l'évaluation du modèle.\n",
    "\n",
    "**Tout se fait dans une seule classe, définie par l'utilisateur, qui doit respecter les conventions suivantes** :\n",
    "* La classe hérite de la classe [lightning.LightningModule](https://lightning.ai/docs/pytorch/stable/common/lightning_module.html#lightningmodule).\n",
    "* Le constructeur fait appel au constructeur de la classe mère.\n",
    "* **Méthode ``__init__()``** : Toutes les couches avec des paramètres entraînables sont initialisées dans le constructeur. Pour éviter de se demander, en cas de doute, si une couche a des paramètres entraînables ou non, autant initialiser toutes les couches et toutes les fonctions d'activation dans le constructeur. Toutes les couches et fonctions d'activation que nous utiliserons sont définies dans le sous-module [torch.nn](https://pytorch.org/docs/stable/nn.html).\n",
    "* **Méthode ``forward()``** : Elle définit comment effectuer une passe avant, c'est-à-dire comment passer de l'entrée à la sortie du réseaux de neurones. Cependant, pour effectuer une passe avant, on n'appelle jamais directement la méthode `forward()` mais on appelle directement l'objet : `self()`.\n",
    "* **Méthode ``training_step()``** : elle définit comment effectuer une étape d'entraînement, c'est-à-dire comment passer d'un lot (*batch*) d'observations à la fonction de coût correspondant à ce lot d'observations.\n",
    "* **Méthode ``configure_optimizers()``** : elle définit l'algorithme d'optimisation à utiliser. Il doit s'agir d'un des algorithmes implémentés dans le sous-module [torch.optim](https://pytorch.org/docs/stable/optim.html#algorithms).\n",
    "\n",
    "Le code ci-dessous définit un perceptron multicouche à deux couches cachées (où les images sont d'abord transformées en vecteurs grâce à la couche `nn.Flatten()`), entraîné par l'algorithme d'optimisation Adam avec l'entropie croisée comme fonction de coût :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "\n",
    "\n",
    "class NeuralNetworkLightning(L.LightningModule):  # La classe hérite de la classe lightning.LightningModule\n",
    "    def __init__(self):\n",
    "        \"\"\"Constructeur.\n",
    "\n",
    "        Dans le constructeur, on exécute le constructeur de la clase mère et on définit\n",
    "        toutes les couches et fonctions d'activation de notre réseau de neurones.\n",
    "        \"\"\"\n",
    "        super().__init__()  # Toujours exécuter le constructeur de la classe mère\n",
    "\n",
    "        # Initialisation de la séquence de couches et de fonctions d'activation\n",
    "        self.sequential = torch.nn.Sequential(\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(28 * 28, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, 10),\n",
    "        )\n",
    "        \n",
    "        # Définition de la fonction de perte\n",
    "        self.loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Implémente la passe avant.\n",
    "\n",
    "        L'argument x est un tenseur correspondant soit à l'entrée une seule\n",
    "        observation soit aux entrées d'un lot d'observations.\n",
    "        \"\"\"\n",
    "        return self.sequential(x)\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        \"\"\"Effectue une étape d'entraînement.\n",
    "\n",
    "        Une étape consiste à passer d'un lot d'observations (l'argument batch)\n",
    "        à l'évaluation de la fonction de coût pour ce lot d'observations.\n",
    "        \"\"\"\n",
    "        X, y = batch  # X correspond aux images, y aux classes\n",
    "        logits = self(X)  # Passe avant, qui renvoie les logits\n",
    "        loss = self.loss(logits, y)  # Évaluation de la fonction de coût\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Configure l'algorithme d'optimisation à utiliser.\"\"\"\n",
    "        optimizer = torch.optim.Adam(self.parameters())\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut toujours visualiser l'architecture de notre réseau de neurones en utilisant la fonction [torchinfo.summary()](https://github.com/TylerYep/torchinfo?tab=readme-ov-file#documentation). En lui fournissant également la taille de l'entrée (en incluant la dimension pour le lot), on peut facilement visualiser la taille de la sortie de chaque couche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "\n",
    "model = NeuralNetworkLightning()\n",
    "summary(model, input_size=(64, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il nous reste maintenant à définir une instance de la classe [lightning.Trainer](https://lightning.ai/docs/pytorch/stable/common/trainer.html) pour définir des hyperparamètres de l'entraînement (comme par exemple le nombre maximum d'époques), puis d'utiliser la méthode `.fit()` pour entraîner notre modèle sur un jeu de données (défini par un *dataloader*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = L.Trainer(max_epochs=5)\n",
    "trainer.fit(model=model, train_dataloaders=dataloader_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut effectuer les remarques suivantes :\n",
    "\n",
    "* On n'a pas besoin de réécrire tous les boucles `for` : PyTorch Lightning s'en occupe lui-même.\n",
    "\n",
    "* Le code est mieux organisé : les différentes étapes sont définies à travers des méthodes spécifiques de la classe.\n",
    "\n",
    "* On n'a pas besoin d'indiquer le type d'appareil (CPU ou GPU) sur lequel on souhaite travailler. C'est un des avantages de PyTorch Lightning : il s'occupe automatiquement de mettre le modèle et les données sur le GPU s'il y en a de disponible. C'est le comportement par défaut, il est bien sûr possible de le changer.\n",
    "\n",
    "* Un dossier `lightning_logs` a été créé dans le répertoire courant. En effet, PyTorch Lightning sauvegarde par défaut certaines informations de l'entraînement. On peut bien entendu personnaliser ce qui est sauvegardé dans ces registres.\n",
    "\n",
    "* Une barre indique la progression de l'entraînement, mais aucune statistique (fonction de perte, précision) n'est affichée pour suivre la *qualité* de l'entraînement.\n",
    "\n",
    "Nous allons utiliser des réglages avancés de PyTorch Lightning pour combler ces manques. Le gain en termes de code sera donc plus limité que dans cette version initiale basique, mais les résultats obtenus seront plus lisibles et plus faciles à analyser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réglages avancés\n",
    "\n",
    "On a réussi à entraîner notre modèle pendant plusieurs époques, mais on n'a aucune information sur la qualité de l'entraînement :\n",
    "\n",
    "* Est-ce que le modèle a convergé ?\n",
    "* Quel est la valeur de la fonction de coût à la fin de l'entraînement ?\n",
    "* À quelle performance peut-on s'attendre de la part de ce modèle entraîné ?\n",
    "\n",
    "Heureusement, PyTorch Lightning est très flexible et nous permet de personnaliser l'entraînement, notamment pour **afficher** et **enregistrer** des informations pertinentes de l'entraînement. On va effectuer les modifications suivantes :\n",
    "\n",
    "* On va rajouter une **étape de validation**, c'est-à-dire qu'à la fin de chaque époque, on va évaluer notre modèle sur un jeu de validation (différent du jeu d'entraînement). Cela nous permet d'évaluer notre modèle sur un jeu de données indépendant du jeu d'entraînement.\n",
    "* On va **afficher davantage d'informations au cours de l'entraînement**, notamment la valeur de la fonction de coût pour certains lots d'observations à intervalle régulier. Cela nous permet de vérifier que la fonction de coût (en général) diminue bien au cours de l'entraînement et de détecter éventuellement du surapprentissage (si la fonction de coût est bien plus faible sur le jeu d'entraînement que le jeu de validation).\n",
    "* On va supprimer les éventuels avertissements affichés par Lightning, qui s'affichent entre les informations que l'on a décidé d'afficher.\n",
    "* Par défaut, Lightning enregistre des informations liées à l'entraînement dans un dossier `lightning_logs` pour être visualisées avec [TensorBoard](https://www.tensorflow.org/tensorboard?hl=fr). Nous allons utiliser un autre enregistreur, [CSVLogger](https://lightning.ai/docs/pytorch/stable/extensions/generated/lightning.pytorch.loggers.CSVLogger.html), qui va enregistrer ces informations dans un fichier CSV que l'on pourra facilement lire pour visualiser les résultats.\n",
    "\n",
    "Il est nécessaire d'utiliser les noms des méthodes spécifiques à chaque opération. Les nouvelles méthodes définies sont les suivantes :\n",
    "* `validation_step()` : effectue une étape de validation.\n",
    "* `test_step()` : effectue une étape d'évaluation.\n",
    "* `on_train_start()` : exécutée au début de l'entraînement, on l'utilise ici pour afficher la version du modèle.\n",
    "* `on_train_epoch_end()` : exécutée au début de chaque époque sur le jeu d'entraînement, on l'utilise ici pour afficher des informations à la fin de chaque époque.\n",
    "\n",
    "Les époques sont exécutées en alternance sur le jeu d'entraînement et sur le jeu de validation, en commençant par le jeu d'entraînement.\n",
    "La méthode `fit()` effectue donc les opérations suivantes :\n",
    "* Époque 1 sur le jeu d'entraînement\n",
    "* Époque 1 sur le jeu de validation\n",
    "* Époque 2 sur le jeu d'entraînement\n",
    "* Époque 2 sur le jeu de validation\n",
    "* etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des messages d'information affichés par PyTorch Lightning\n",
    "import logging\n",
    "logging.getLogger(\"lightning\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"lightning.pytorch.utilities.rank_zero\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"lightning.pytorch.accelerators.cuda\").setLevel(logging.WARNING)\n",
    "\n",
    "# Suppression des avertissements liés aux dataloaders\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \".*does not have many workers.*\")\n",
    "\n",
    "\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "\n",
    "class NeuralNetworkLightningAdvanced(L.LightningModule):  # La classe hérite de la classe lightning.LightningModule\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Constructeur.\n",
    "        \n",
    "        Dans le constructeur, on exécute le constructeur de la clase mère et on définit\n",
    "        toutes les couches et fonctions d'activation de notre réseau de neurones.\n",
    "        \"\"\"\n",
    "        super().__init__()  # Toujours exécuter le constructeur de la classe mère\n",
    "\n",
    "        # Initialisation de la séquence de couches et de fonctions d'activation\n",
    "        self.sequential = torch.nn.Sequential(\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(28 * 28, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "        # Initialisation de la fonction de perte\n",
    "        self.loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        # Initialisation des métriques\n",
    "        # IMPORTANT : il faut créer une instance pour chaque jeu car la métrique\n",
    "        # accumule les résultats intermédiaires calculés sur chaque lot.\n",
    "        self.accuracy_train = Accuracy(task=\"multiclass\", num_classes=10)\n",
    "        self.accuracy_val = Accuracy(task=\"multiclass\", num_classes=10)\n",
    "        self.accuracy_test = Accuracy(task=\"multiclass\", num_classes=10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Implémente la passe avant.\n",
    "        \n",
    "        L'argument x est un tenseur correspondant soit à l'entrée une seule\n",
    "        observation soit aux entrées d'un lot d'observations.\n",
    "        \"\"\"\n",
    "        return self.sequential(x)\n",
    "    \n",
    "    def step(self, batch, dataset):\n",
    "        \"\"\"Effectue une étape.\n",
    "\n",
    "        Une étape consiste à passer d'un lot d'observations (l'argument batch)\n",
    "        à l'évaluation de la fonction de coût pour ce lot d'observations.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch : tuple\n",
    "            Un lot d'observations. Le premier élément du tuple est le lot\n",
    "            des entrées, le second est le lot des labels.\n",
    "            \n",
    "        dataset : {\"training\", \"validation\", \"test\"}\n",
    "            Jeu de données utilisé.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        loss : Tensor, shape = (1,)\n",
    "            La fonction de coût pour ce lot d'observations.\n",
    "        \"\"\"\n",
    "        X, y = batch  # X correspond aux images, y aux classes\n",
    "        logits = self(X)  # Passe avant, qui renvoie les logits\n",
    "        loss = self.loss(logits, y)  # Évaluation de la fonction de coût\n",
    "        y_pred = logits.argmax(1)  # Prédictions du modèle\n",
    "        \n",
    "        if dataset == \"training\":\n",
    "            metric = self.accuracy_train\n",
    "            name = \"train\"\n",
    "            bar_step = True\n",
    "        elif dataset == \"validation\":\n",
    "            metric = self.accuracy_val\n",
    "            name = \"val\"\n",
    "            bar_step = False\n",
    "        else:\n",
    "            metric = self.accuracy_test\n",
    "            name = \"test\"\n",
    "            bar_step = False\n",
    "\n",
    "        acc = metric(y_pred, y)  # Évaluation de la métrique\n",
    "        self.log(f\"loss_{name}\", loss, prog_bar=bar_step, on_step=bar_step, on_epoch=True)\n",
    "        self.log(f\"accuracy_{name}\", acc, prog_bar=bar_step, on_step=bar_step, on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        \"\"\"Effectue une étape d'entraînement.\"\"\"\n",
    "        return self.step(batch, \"training\")\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        \"\"\"Effectue une étape de validation.\"\"\"\n",
    "        return self.step(batch, \"validation\")\n",
    "\n",
    "    def test_step(self, batch):\n",
    "        \"\"\"Effectue une étape d'évaluation.\"\"\"\n",
    "        return self.step(batch, \"test\")\n",
    "    \n",
    "    def on_train_start(self):\n",
    "        \"\"\"Code exécuté au début de l'entraînement.\"\"\"\n",
    "        string = f\"Version {self.trainer.logger.version}\"\n",
    "        print(f\"{string}\\n{'=' * len(string)}\\n\")\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        \"\"\"Code exécuté à la fin de chaque époque d'entraînement.\"\"\"\n",
    "        metrics = self.trainer.callback_metrics\n",
    "        string = (f\"\"\"\n",
    "            Époque {self.trainer.current_epoch + 1} / {self.trainer.max_epochs}\n",
    "            ------------------------------------------------\n",
    "            |     Jeu      | Fonction de perte | Précision |\n",
    "            | ------------ | ----------------- | --------- |\n",
    "            | Entraînement |{metrics['loss_train'].item():^19.5f}|{metrics['accuracy_train'].item():^11.3%}|\n",
    "            |  Validation  |{metrics['loss_val'].item():^19.5f}|{metrics['accuracy_val'].item():^11.3%}|\n",
    "            ------------------------------------------------\n",
    "        \"\"\")\n",
    "        string = '\\n'.join([line.strip() for line in string.split('\\n')])\n",
    "        print(string)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Configure l'algorithme d'optimisation à utiliser.\"\"\"\n",
    "        optimizer = torch.optim.Adam(self.parameters())\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks import TQDMProgressBar\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "\n",
    "\n",
    "model = NeuralNetworkLightningAdvanced()\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=20,\n",
    "    enable_model_summary=False,  # supprimer le résumé du modèle\n",
    "    logger=CSVLogger('.'),  # sauvegarder les résultats dans un fichier CSV\n",
    "    num_sanity_val_steps=0,  # ne pas effectuer d'étape de validation avant l'entraînement\n",
    "    callbacks=[TQDMProgressBar(refresh_rate=100)]  # mettre à jour la barre de progression tous les 100 lots\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    model=model,\n",
    "    train_dataloaders=dataloader_train,\n",
    "    val_dataloaders=dataloader_val\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous avez peut-être remarqué que le dossier `lightning_logs` contient plusieurs sous-dossiers `version_X`. En effet, un des avantages est que les résultats sont sauvegardés à chaque fois dans un nouveau dossier, ce qui veut dire qu'on peut facilement sauvegarder des résultats pour plusieurs expériences différentes.\n",
    "\n",
    "Dans la méthode `step()`, qui est ensuite appelée par les méthodes `training_step()`, `validation_step()` et `test_step()`, vous avez peut-être remarqué les lignes de code suivantes :\n",
    "```python\n",
    "self.log(f\"loss_{name}\", loss, prog_bar=bar_step, on_step=bar_step, on_epoch=True)\n",
    "self.log(f\"accuracy_{name}\", acc, prog_bar=bar_step, on_step=bar_step, on_epoch=True)\n",
    "```\n",
    "Pour le jeu d'entraînement `bar_step=True`, tandis que pour les jeux de validation et d'évaluation, `bar_step=False`.\n",
    "On demande à PyTorch Lightning de sauvegarder les valeurs de la fonction de perte (*loss*) et de la précision (*accuracy*) à la fin de chaque itération (`on_step=True`) et à la fin de chaque époque (`on_epoch=True`) sur le jeu d'entraînement, ainsi que de les afficher dans la barre de progression (`prog_bar=True`), mais uniquement à la fin de chaque époque (`on_step=False, on_epoch=True`) sur les jeux de validation et d'évaluation.\n",
    "L'avantage de sauvegarder les résultats à chaque itération est qu'on peut afficher les résultats dans la barre de progression : on n'a plus besoin d'afficher une nouvelle ligne dans la sortie standard pour certaines itérations de temps en temps.\n",
    "\n",
    "Ces résultats sont sauvegardés dans le fichier `metrics.csv`. On peut maintenant facilement afficher les résultats obtenus en chargeant les donnés contenues dans ce fichier :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_accuracy(savedir='.', version=None):\n",
    "    \"\"\"Affiche les courbes de la fonction de perte et d'accuracy.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    savedir : str (default = '.')\n",
    "        Chemin où les résultats sont sauvegardés.\n",
    "\n",
    "    version : int or None (default = None)\n",
    "        Numéro de la version du modèle.\n",
    "    \"\"\"\n",
    "    # Récupère les résultats sous la forme d'un DataFrame\n",
    "    import matplotlib.pyplot as plt\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    if version is None:\n",
    "        version = max([\n",
    "            int(folder.split('version_')[1])\n",
    "            for folder in os.listdir(os.path.join(savedir, 'lightning_logs'))\n",
    "            if folder.startswith('version')\n",
    "        ])\n",
    "    df = pd.read_csv(os.path.join(savedir, 'lightning_logs', f'version_{version}', 'metrics.csv'))\n",
    "    df['epoch'] += 1  # On commence à compter à partir de 1\n",
    "\n",
    "    loss_train = df.dropna(subset='loss_train_epoch').set_index('epoch')['loss_train_epoch']\n",
    "    loss_val = df.dropna(subset='loss_val').set_index('epoch')['loss_val']\n",
    "\n",
    "    accuracy_train = df.dropna(subset='accuracy_train_epoch').set_index('epoch')['accuracy_train_epoch']\n",
    "    accuracy_val = df.dropna(subset='accuracy_val').set_index('epoch')['accuracy_val']\n",
    "\n",
    "    # Affiche les résultats\n",
    "    plt.figure(figsize=(13, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(loss_train.index, loss_train.to_numpy(), 'o-', label='Entraînement');\n",
    "    plt.plot(loss_val.index, loss_val.to_numpy(), 'o-', label='Validation');\n",
    "    plt.xlabel('Époque')\n",
    "    plt.ylabel('Fonction de perte')\n",
    "    plt.legend();\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(accuracy_train.index, accuracy_train.to_numpy(), 'o-', label='Entraînement');\n",
    "    plt.plot(accuracy_val.index, accuracy_val.to_numpy(), 'o-', label='Validation');\n",
    "    plt.xlabel('Époque')\n",
    "    plt.ylabel('Précision')\n",
    "    plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que le modèle commence à souffrir de surapprentissage : la performance sur le jeu de validation stagne assez vite, tandis qu'elle continue sans cesse de s'améliorer sur le jeu d'entraînement.\n",
    "\n",
    "Les méthodes `validate_step()` et `test_step()` permettent également d'appeler les méthodes `validate()` et `test()` sur les instances de `Trainer` respectivement.\n",
    "\n",
    "La méthode `validate()` permet de calculer la fonction de coût et la précision sur le jeu de validation (informations que l'on a déjà ici puisqu'on calcule ces scores à la fin de chaque époque pendant l'entraînement, mais on illustre tout de même son fonctionnement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.validate(model, dataloader_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De même, la méthode `test()` permet de calculer la fonction de coût et la précision sur le jeu d'évaluation.\n",
    "Néanmoins, nous n'avons pas de jeu d'évaluation ici, donc nous verrons son utilisation dans d'autres notebooks.\n",
    "Si on avait une variable `dataloader_test` correspondant au *dataloader* pour le jeu d'évaluation, le code serait le suivant :\n",
    "```python\n",
    "trainer.test(model, dataloader_test)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
