{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99742860",
   "metadata": {},
   "source": [
    "**Avant de débuter ce TP** :\n",
    "\n",
    "1. **Changez le type d'exécution sur Google Colab** : `Exécution > Modifiez le type d'exécution > T4 GPU`\n",
    "2. **Installez les paquets ci-dessous** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90642501",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install lightning torchmetrics torchinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1be5da",
   "metadata": {},
   "source": [
    "3. Exécutez ce code pour supprimer quelques messages et avertissements éventuellement affichés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a09bec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger(\"lightning\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"lightning.pytorch.utilities.rank_zero\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"lightning.pytorch.accelerators.cuda\").setLevel(logging.WARNING)\n",
    "logger = logging.getLogger(\"lightning\")\n",
    "logger.propagate = False\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \".*does not have many workers.*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0710cb96",
   "metadata": {},
   "source": [
    "# Génération d'images de chiffres par auto-encodeur variationnel\n",
    "\n",
    "\n",
    "\n",
    "### Exercice 1\n",
    "\n",
    "Créez les *datasets* puis les *dataloaders* pour les jeux d'entraînement et de validation du jeu de données MNIST, implémentée dans la classe [torchvision.datasets.MNIST()](https://pytorch.org/vision/main/generated/torchvision.datasets.MNIST.html), en utilisant les informations suivantes :\n",
    "\n",
    "* Concernant les *datasets*, n'oubliez pas de transformer les entrées brutes, qui sont des images PIL d'entiers entre $0$ et $255$, en tenseurs de nombres flottants à $32$ bits compris enter $0.0$ et $1.0$.\n",
    "\n",
    "* Concernant les *dataloaders*, on utilisera des lots de taille $64$. Les observations sont mélangées sur le jeu d'entraînement, mais pas sur le jeu de validation.\n",
    "\n",
    "Vous pouvez vous inspirer du code du TP 2.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e819fdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f59557",
   "metadata": {},
   "source": [
    "### Exercice 2\n",
    "\n",
    "Calculez la taille d'une image. On admettra que toutes les images ont la même taille."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640de705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770eab4a",
   "metadata": {},
   "source": [
    "On visualise quelques observations du jeu d'entraînement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2366f6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(dataset_train), size=(1,)).item()\n",
    "    img, label = dataset_train[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(f\"{label}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d06929f",
   "metadata": {},
   "source": [
    "## Architecture et entraînement du modèle\n",
    "\n",
    "Un auto-encodeur variationnel est une variante générative de l'auto-encodeur.\n",
    "\n",
    "### Architecture\n",
    "\n",
    "L'image ci-dessous résume l'architecture que vous allez implémenter :\n",
    "\n",
    "[<img src=\"https://raw.githubusercontent.com/johannfaouzi/apprentissage-profond-ensai/main/figures/vae_computation_graph.png\" width=\"650\"/>](https://raw.githubusercontent.com/johannfaouzi/apprentissage-profond-ensai/main/figures/vae_computation_graph.png)\n",
    "\n",
    "Un auto-encodeur est composé de deux éléments : l'encodeur (dénoté par $q$ sur l'image) puis le décodeur (dénoté par $p$ sur l'image).\n",
    "\n",
    "L'entrée de l'encodeur, dénotée par $x$, est une image de chiffre.\n",
    "La sortie de l'encodeur est composée de deux vecteurs : la moyenne $\\mu$ et le logarithme de la variance $\\log(\\sigma^2)$ d'une distribution gaussienne multivariée $\\mathcal{N}(\\mu, \\sigma^2)$.\n",
    "On suppose que la matrice de covariance est diagonale, c'est pourquoi elle est caractérisée par un simple vecteur (correspondant à la diagonale de cette matrice).\n",
    "\n",
    "L'entrée du décodeur est une variable aléatoire générée selon la loi $\\mathcal{N}(\\mu, \\sigma^2)$.\n",
    "Pour obtenir une telle variable, on génère d'abord un vecteur aléatoire ${z}$ selon la loi $\\mathcal{N}(0, I)$, puis on applique la transformation affine $\\mu + \\sigma \\odot z$ qui suit la loi $\\mathcal{N}(\\mu, \\sigma^2)$.\n",
    "\n",
    "La dimension de l'espace latent, dénotée par `latent_dim`, sera un hyperparamètre de notre classe.\n",
    "On utilisera la valeur par défaut, c'est-à-dire `latent_dim = 8`.\n",
    "\n",
    "Concernant l'encodeur, vous implémenterez l'architecture séquentielle suivante :\n",
    "\n",
    "* Couche d'aplatissement\n",
    "* Couche linéaire avec $512$ variables en sortie\n",
    "* Fonction d'activation ReLU\n",
    "* Couche linéaire avec $256$ variables en sortie\n",
    "* Fonction d'activation ReLU\n",
    "* Couche linéaire avec $2 \\times$ `latent_dim` variables en sortie\n",
    "\n",
    "La sortie de l'encodeur est un tenseur à une dimension, c'est-à-dire un vecteur, de taille $2 \\times$ `latent_dim` car il contient à la fois le tenseur de taille `latent_dim` pour la moyenne $\\mu$ et le tenseur de taille `latent_dim` pour le logarithme de la variance $\\log(\\sigma^2)$.\n",
    "\n",
    "Concernant le décodeur, vous implémenterez l'architecture séquentielle suivante :\n",
    "\n",
    "* Couche linéaire avec $256$ variables en sortie\n",
    "* Fonction d'activation ReLU\n",
    "* Couche linéaire avec $512$ variables en sortie\n",
    "* Fonction d'activation ReLU\n",
    "* Couche linéaire avec $784$ variables en sortie\n",
    "* Fonction d'activation Sigmoïde\n",
    "* Couche de désaplatissement\n",
    "\n",
    "Le rôle de la dernière couche est de transformer le vecteur en image, c'est-à-dire un tenseur à trois dimensions.\n",
    "\n",
    "Voici les liens vers la documentation des outils pertinents pour construire ces deux architectures :\n",
    "[torch.nn.Flatten()](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html),\n",
    "[torch.nn.Linear()](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html),\n",
    "[torch.nn.ReLU()](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html),\n",
    "[torch.nn.Sigmoid()](https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html) et\n",
    "[torch.nn.Unflatten()](https://pytorch.org/docs/stable/generated/torch.nn.Unflatten.html).\n",
    "\n",
    "Pour générer des variables aléatoires indépendantes selon la loi gaussienne centrée réduite, vous pouvez utiliser la fonction [torch.randn()](https://pytorch.org/docs/main/generated/torch.randn.html).\n",
    "\n",
    "### Fonction de perte\n",
    "\n",
    "La fonction de perte $J$, composée de deux termes différents, est définie par l'équation suivante :\n",
    "$$\n",
    "    J(\\tilde{x}, x) = \\text{BCE}(\\tilde{x}, x) - \\lambda \\times KL\n",
    "$$\n",
    "où :\n",
    "* $x$ est l'image originale (en entrée de l'encodeur) et $\\tilde{x}$ est l'image reconstruite (en sortie du décodeur),\n",
    "$\\text{BCE}(\\tilde{x}, x)$ est l'entropie croisée entre $\\tilde{x}$ et $x$ : elle correspond à l'**erreur de reconstruction**.\n",
    "* $KL$ est la [divergence de Kullback-Leibler](https://fr.wikipedia.org/wiki/Divergence_de_Kullback-Leibler) entre la distribution utilisée $\\mathcal{N}(\\mu, \\sigma^2)$ et la distribution cible $\\mathcal{N}(0, I)$ : elle incite l'espace latent à suivre une distribution gaussienne isotropique. Sa formule est la suivante :\n",
    "$$\n",
    "    KL = \\frac{1}{2} \\sum_{i=1}^p \\left( 1 + \\log(\\sigma_i^2) - \\mu_i^2 - \\sigma_i^2 \\right)\n",
    "$$\n",
    "où $\\mu = (\\mu_1, \\ldots, \\mu_p)$, $\\sigma = (\\sigma_1, \\ldots, \\sigma_p)$ et $p$ est la dimension de l'espace latent.\n",
    "* $\\lambda$ est le terme de pondération de la divergence de Kullback-Leibler par rapport à l'entropie croisée binaire.\n",
    "\n",
    "Voici le lien vers la documentation de [torch.nn.BCELoss()](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html).\n",
    "Pour la divergence de Kullback-Leibler, vous pouvez utiliser les fonctions \n",
    "[torch.sum()](https://pytorch.org/docs/stable/generated/torch.sum.html),\n",
    "[torch.exp()](https://pytorch.org/docs/stable/generated/torch.exp.html) et\n",
    "[torch.pow()](https://pytorch.org/docs/stable/generated/torch.pow.html).\n",
    "\n",
    "### Évaluation\n",
    "\n",
    "Pour comparer les images reconstruites avec les images originales, nous utiliserons la [*structural similarity index measure*](https://en.wikipedia.org/wiki/Structural_similarity_index_measure).\n",
    "Plus d'explications sur cette métrique seront fournies dans un prochain notebook.\n",
    "Tout ce dont vous avez besoin de savoir pour le moment est que ses valeurs sont comprises entre $0$ (le pire) et $1$ (le meilleur).\n",
    "\n",
    "### Exercice 3\n",
    "\n",
    "Complétez les méthodes `__init__()`,  `encode()`, `reparametrize()`, `decode()`, `forward()` et `loss_function()` de la classe `VAE()` en utilisant les informations fournies ci-dessus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3587b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "from torchmetrics.image import StructuralSimilarityIndexMeasure\n",
    "\n",
    "\n",
    "class VAE(L.LightningModule):\n",
    "    \"\"\"Classe pour l'auto-encodeur variationnel.\"\"\"\n",
    "    def __init__(self, latent_dim=8):\n",
    "        super().__init__()\n",
    "        \n",
    "        if not (isinstance(latent_dim, int) and latent_dim > 0):\n",
    "            raise ValueError(\n",
    "                \"La dimension de l'espace latent doit être un entier strictement positif.\"\n",
    "            )\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        ### BEGIN TODO ###\n",
    "        # Initialisation de l'encodeur\n",
    "        # self.encoder = \n",
    "        \n",
    "        # Initialisation du décodeur\n",
    "        # self.decoder = \n",
    "        \n",
    "        # Initialisation de l'entropie croisée\n",
    "        # self.bce_loss = \n",
    "\n",
    "        # Pondération de la KL divergence comparée à l'entropie croisée binaire\n",
    "        self.lambda_kld = 1e-4\n",
    "    \n",
    "        # Initialisation des métriques\n",
    "        self.metric_train = StructuralSimilarityIndexMeasure()\n",
    "        self.metric_val = StructuralSimilarityIndexMeasure()\n",
    "        #### END TODO ####\n",
    "\n",
    "    def encode(self, x):\n",
    "        \"\"\"Effectue une passe avant de l'encodeur.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : Tensor, shape = [batch_size, 1, 28, 28]\n",
    "            Lots de vraies images.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        mu : Tensor, shape = [batch_size, latent_dim]\n",
    "            Moyennes des distributions gaussiennes.\n",
    "            \n",
    "        log_var : Tensor, shape = [batch_size, latent_dim]\n",
    "            Logarithmes des variance des distributions gaussiennes.\n",
    "        \"\"\"\n",
    "        ### BEGIN TODO ###\n",
    "        # mu = \n",
    "        # log_sigma = \n",
    "        #### END TODO ####\n",
    "        return mu, log_sigma\n",
    "\n",
    "    def reparametrize(self, mu, log_var):\n",
    "        \"\"\"Reparamétrisation du modèle.\n",
    "        \n",
    "        On génère une variable aléatoire `z` selon la loi N(0, 1) et,\n",
    "        grâce à la moyenne et au logarithme de la variance fournies en\n",
    "        arguments, on génère une variable aléatoire selon la loi N(mu, var)\n",
    "        par la transformation affine mu + z * std.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        mu : Tensor, shape = [batch_size, latent_dim]\n",
    "            Moyenne de la distribution gaussienne.\n",
    "            \n",
    "        log_var : Tensor, shape = [batch_size, latent_dim]\n",
    "            Logarithme de la variance de la distribution gaussienne.\n",
    "        \"\"\"\n",
    "        ### BEGIN TODO ###\n",
    "        # z = \n",
    "        #### END TODO ####\n",
    "        return z\n",
    "    \n",
    "    def decode(self, z):\n",
    "        \"\"\"Effectue une passe avant du décodeur.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        z : Tensor, shape = [batch_size, latent_dim]\n",
    "            Variables aléatoires selon la loi N(mu, var)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        x_reconstructed : Tensor, shape = [batch_size, 1, 28, 28]\n",
    "            Images générées.\n",
    "        \"\"\"\n",
    "        ### BEGIN TODO ###\n",
    "        # x_reconstructed = \n",
    "        #### END TODO ####\n",
    "        return x_reconstructed\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Effectue une passe avant.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : Tensor, shape = [batch_size, 1, 28, 28]\n",
    "            Lots de vraies images.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        x_renconstructed : Tensor, shape = [batch_size, 1, 28, 28]\n",
    "            Lots d'images générées.\n",
    "        \n",
    "        mu : Tensor, shape = [batch_size, latent_dim]\n",
    "            Moyenne de la distribution gaussienne.\n",
    "            \n",
    "        log_var : Tensor, shape = [batch_size, latent_dim]\n",
    "            Logarithme de la variance de la distribution gaussienne.\n",
    "        \"\"\"\n",
    "        ### BEGIN TODO ###\n",
    "        # mu, log_var = \n",
    "        # z = \n",
    "        # x_renconstructed = \n",
    "        #### END TODO ####\n",
    "        return x_renconstructed, mu, log_var\n",
    "    \n",
    "    def loss_function(self, x_reconstructed, x, mu, log_var):\n",
    "        \"\"\"Calcule la fonction de coût d'un VAE.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : Tensor, shape = [batch_size, 1, 28, 28]\n",
    "            Lots d'images.\n",
    "        \n",
    "        x_reconstructed : Tensor, shape = [batch_size, 1, 28, 28]\n",
    "            Lots d'images reconstruites.\n",
    "        \n",
    "        mu : Tensor, shape = [batch_size, latent_dim]\n",
    "            Moyenne de la distribution gaussienne.\n",
    "            \n",
    "        log_var : Tensor, shape = [batch_size, latent_dim]\n",
    "            Logarithme de la variance de la distribution gaussienne.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        loss : Tensor, shape = []\n",
    "            Évaluation de la fonction de coût.\n",
    "        \"\"\"\n",
    "        ### BEGIN TODO ###\n",
    "        # bce = \n",
    "        # kld = \n",
    "        #### END TODO ####\n",
    "        return bce - self.lambda_kld * kld\n",
    "\n",
    "    def step(self, batch, dataset):\n",
    "        \"\"\"Effectue une étape.\n",
    "\n",
    "        Une étape consiste à passer d'un lot d'observations (l'argument batch)\n",
    "        à l'évaluation de la fonction de coût pour ce lot d'observations.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch : tuple\n",
    "            Un lot d'observations. Le premier élément du tuple est le lot\n",
    "            des entrées, le second est le lot des labels.\n",
    "            \n",
    "        dataset : {\"training\", \"validation\"}\n",
    "            Jeu de données utilisé.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        loss : Tensor, shape = []\n",
    "            La fonction de coût pour ce lot d'observations.\n",
    "        \"\"\"\n",
    "        x, _ = batch\n",
    "        x_reconstructed, mu, log_var = self(x)\n",
    "        loss = self.loss_function(x_reconstructed, x, mu, log_var)\n",
    "\n",
    "        if dataset == \"training\":\n",
    "            name = \"train\"\n",
    "            metric = self.metric_train\n",
    "            bar_step = True\n",
    "        else:\n",
    "            name = \"val\"\n",
    "            metric = self.metric_val\n",
    "            bar_step = False\n",
    "\n",
    "        ssim = metric(x_reconstructed, x)\n",
    "        self.log(f\"loss_{name}\", loss, prog_bar=bar_step, on_step=bar_step, on_epoch=True)\n",
    "        self.log(f\"ssim_{name}\", ssim, prog_bar=bar_step, on_step=bar_step, on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        return self.step(batch, \"training\")\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        return self.step(batch, \"validation\")\n",
    "\n",
    "    def on_train_start(self):\n",
    "        \"\"\"Code exécuté au début de l'entraînement.\"\"\"\n",
    "        string = f\"Version {self.trainer.logger.version}\"\n",
    "        print(f\"{string}\\n{'=' * len(string)}\\n\")\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        \"\"\"Code exécuté à la fin de chaque époque d'entraînement.\"\"\"\n",
    "        metrics = self.trainer.callback_metrics\n",
    "        string = (f\"\"\"\n",
    "            Époque {self.trainer.current_epoch + 1} / {self.trainer.max_epochs}\n",
    "            -----------------------------------------------\n",
    "            |     Jeu      | Fonction de perte |   SSIM   |\n",
    "            | ------------ | ----------------- | -------- |\n",
    "            | Entraînement |{metrics['loss_train'].item():^19.5f}|{metrics['ssim_train'].item():^10.6f}|\n",
    "            |  Validation  |{metrics['loss_val'].item():^19.5f}|{metrics['ssim_val'].item():^10.6f}|\n",
    "            -----------------------------------------------\n",
    "        \"\"\")\n",
    "        string = '\\n'.join([line.strip() for line in string.split('\\n')])\n",
    "        print(string)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Configure l'algorithme d'optimisation à utiliser.\"\"\"\n",
    "        optimizer = torch.optim.Adam(self.parameters())\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0104169",
   "metadata": {},
   "source": [
    "### Exercice 4\n",
    "\n",
    "Affichez un résumé de l'architecture. Combien de paramètres entraînables a-t-elle ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85d7d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8675ed",
   "metadata": {},
   "source": [
    "**Réponse** : TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de11590c",
   "metadata": {},
   "source": [
    "### Exercice 5\n",
    "\n",
    "Entraînez votre modèle pendant $20$ époques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63b09b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aabbb63",
   "metadata": {},
   "source": [
    "Maintenant que l'auto-encodeur variationnel est entraîné, on souhaite visualiser des images générées par ce modèle.\n",
    "La première étape est de générer des images avec le modèle.\n",
    "\n",
    "On rappelle le processus de génération d'un auto-encodeur variationnel :\n",
    "\n",
    "* On génère une variable aléatoire $z$ selon la loi normale centrée réduite : $z \\sim \\mathcal{N}(0, 1)$\n",
    "* On fournit $z$ en entrée du décodeur qui renvoie l'image correspondante.\n",
    "\n",
    "### Exercice 6\n",
    "\n",
    "La fonction `generate_digit_images()` permet de générer et de renvoyer $64$ images générées par un auto-encodeur variationnel entraîné.\n",
    "Complétez le code manquant dans cette fonction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6be8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_digit_images(model):\n",
    "    \"\"\"Génère des images de chiffres.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : VAE\n",
    "        Auto-encodeur variationnel entraîné.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    x_gen : Tensor, shape = [64, 1, 28, 28]\n",
    "        64 images de chiffres générées par le modèle.\n",
    "    \"\"\"\n",
    "    ### BEGIN TODO ###\n",
    "    # x_gen = \n",
    "    #### END TODO ####\n",
    "    return x_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c711c418",
   "metadata": {},
   "source": [
    "### Exercice 7\n",
    "\n",
    "Utilisez la fonction `plot_generated_images()` définie ci-dessous pour afficher des images générées par votre auto-encodeur variationnel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0d4058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_generated_images(model):\n",
    "    x_gen = torch.squeeze(generate_digit_images(model).detach().cpu())\n",
    "    \n",
    "    plt.figure(figsize=(6, 6))\n",
    "\n",
    "    plt.imshow(torch.cat([\n",
    "        torch.cat([x_gen[i] for i in range(8 * j, 8 * (j + 1))])\n",
    "        for j in range(8)\n",
    "    ], dim=1), cmap='gray')\n",
    "\n",
    "    plt.xticks([]); plt.yticks([]);\n",
    "    plt.title(\"Generated images\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68419e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
