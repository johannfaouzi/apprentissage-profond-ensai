{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6db090b9",
   "metadata": {},
   "source": [
    "**Avant de débuter ce TP** :\n",
    "\n",
    "1. **Changez le type d'exécution sur Google Colab** : `Exécution > Modifiez le type d'exécution > T4 GPU`\n",
    "2. **Installez les paquets ci-dessous** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40edf187",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install lightning torchmetrics torchinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8ad565",
   "metadata": {},
   "source": [
    "3. Exécutez ce code pour supprimer quelques messages et avertissements éventuellement affichés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98092bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger(\"lightning\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"lightning.pytorch.utilities.rank_zero\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"lightning.pytorch.accelerators.cuda\").setLevel(logging.WARNING)\n",
    "logger = logging.getLogger(\"lightning\")\n",
    "logger.propagate = False\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \".*does not have many workers.*\")\n",
    "warnings.filterwarnings(\"ignore\", \".*You are using `torch.load` with `weights_only=False`.*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a25f83",
   "metadata": {},
   "source": [
    "# Prévision de la future consommation électrique\n",
    "\n",
    "Nous allons travailler sur un jeu de données appelé [short-term electricity load forecasting](https://data.mendeley.com/datasets/byx7sztj59/1).\n",
    "L'objectif est de prédire la consommation électrique au Panama pendant à un moment donné.\n",
    "Les données disponibles vont du 3 janvier 2015 au 26 juin 2020 à l'échelle horaire (une observation toutes les heures) et incluent non la consommation d'électricité mais aussi des données météorologiques dans zones géographiques du Panama et des indicatrices pour les jours fériés et les jours d'école.\n",
    "\n",
    "## (Télé)chargement des données\n",
    "\n",
    "La fonction `load_dataset` permet de charger (et télécharger si besoin) le jeu de données dans un [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c89dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_dataset(path='data'):\n",
    "    \"\"\"Load the dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        Chemin du répertoire.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : DataFrame\n",
    "        Données.\n",
    "\n",
    "    \"\"\"\n",
    "    import os\n",
    "    from urllib.request import urlretrieve\n",
    "\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        \n",
    "    file = \"continuous-dataset.csv\"\n",
    "\n",
    "    # Download the file if necessary\n",
    "    if not os.path.isfile(os.path.join(path, file)):\n",
    "        url = (\n",
    "            'https://raw.githubusercontent.com/johannfaouzi/apprentissage-profond-ensai/'\n",
    "            'main/data/electricity-load/continuous-dataset.csv'\n",
    "        )\n",
    "        urlretrieve(url, os.path.join(path, file))\n",
    "\n",
    "    return pd.read_csv(os.path.join(path, file), index_col=0, parse_dates=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301892b1",
   "metadata": {},
   "source": [
    "Il suffit d'exécuter la fonction pour (télé)charger les trois jeux de données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d891c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889265ee",
   "metadata": {},
   "source": [
    "Visualisons le jeu de données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2f0068",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7378e18a",
   "metadata": {},
   "source": [
    "Il y a $48\\ 048$ observations et $16$ variables :\n",
    "* `nat_demand` correspond à la consommation électrique nationale.\n",
    "* `T2M_toc`, `T2M_san` et `T2M_dav` correspondent à la température à deux mètres à Tocumen, Santiago et David respectivement.\n",
    "* `QV2M_toc`, `QV2M_san` et `QV2M_dav` correspondent à l'humidité à deux mètres à Tocumen, Santiago et David respectivement.\n",
    "* `TQL_toc`, `TQL_san` et `TQL_dav` correspondent au niveau de précipitations à Tocumen, Santiago et David respectivement.\n",
    "* `Holiday_ID` est un entier indiquant le type de jour férié (23 valeurs uniques)\n",
    "* `holiday` est une variable binaire indiquant si le jour est férié ou non.\n",
    "* `school` est une variable binaire indiquant si le jour est un jour d'école ou non.\n",
    "\n",
    "L'objectif principal de ce notebook est d'illustrer l'utilisation de réseaux de neurones récurrents et non d'obtenir le meilleur modèle possible.\n",
    "On va donc effectuer un prétraitement des données pour faciliter l'utilisation de réseaux de neurones récurrents.\n",
    "\n",
    "On va tout d'abord supprimer la colonne `Holiday_ID`, non pas parce qu'elle n'est pas pertinente, mais simplement pour ne pas avoir à la traiter.\n",
    "Afin de simplifier la tâche et d'enlever la saisonnalité journalière, on va également rééchantillonner le jeu de données et prendre la valeur moyenne des variables sur chaque journée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78480f90",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = df.drop('Holiday_ID', axis=1).resample('D').mean()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395e6012",
   "metadata": {},
   "source": [
    "Il ne reste plus que $2003$ observations et $15$ variables.\n",
    "\n",
    "Visualisons la série temporelle dont on cherche à prédire les valeurs futures, c'est-à-dire `nat_demand` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517c0a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nat_demand'].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a72da5",
   "metadata": {},
   "source": [
    "On observe une chute de la consommation électrique peu après le début de l'année 2020, très probablement en lien avec la pandémie de Covid-19.\n",
    "Pour éviter d'évaluer le modèle sur cette période, on va se limiter aux données jusqu'à la fin de l'année 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7696712d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df.index.year <= 2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6f8d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe6a1eb",
   "metadata": {},
   "source": [
    "Le jeu de données final contient donc $1824$ observations et $15$ variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50fcdad",
   "metadata": {},
   "source": [
    "## Jeux d'entraînement, de validation et d'évaluation - Normalisation des données\n",
    "\n",
    "La séparation du jeu complet en jeux d'entraînement, de validation et d'évaluation est naturellement différente pour des données temporelles car les observations ne sont pas indépendantes les unes des autres.\n",
    "La séparation se fait également au niveau temporel.\n",
    "Schématiquement, l'entraînement correspond au passé, la validation au présent et l'évaluation au futur.\n",
    "\n",
    "Le `DataFrame` est déjà ordonné chronologiquement.\n",
    "Il est donc nécessaire de définir deux dates limites pour séparer les jeux d'entraînement de validation d'une part, et les jeu de validation et d'évaluation d'autre part.\n",
    "On va utiliser les années 2015 à 2017 pour le jeu d'entraînement, l'année 2018 pour le jeu de validation et l'année 2019 pour l'évaluation.\n",
    "\n",
    "Vous avez probablement remarqué que les différentes variables dans le `DataFrame` n'ont pas les mêmes échelles : les variables pour la température ont par exemple des valeurs bien plus élevées que celles pour l'humidité et pour les précipitations.\n",
    "De telles différences d'échelles peuvent compliquer l'entraînement d'un modèle d'apprentissage automatique, et c'est d'autant plus vrai pour un réseau de neurones.\n",
    "On va donc normaliser les données.\n",
    "Néanmoins, les jeux de validation et d'évaluation ne doivent pas servir pour l'entraînement, et l'estimation des paramètres utilisés pour la normalisation fait partie de l'entraînement.\n",
    "Il est donc nécessaire de n'utiliser que les données d'entraînement pour estimer ces paramètres.\n",
    "Les variables binaires n'ont pas besoin d'être modifiées.\n",
    "\n",
    "Il est temps d'écrire le code pour effectuer ce travail.\n",
    "Comme les données sont déjà ordonnées chronologiquement, il nous suffit de trouver les indices du premier jour des années 2019 et 2020 pour effectuer la sépration en trois jeux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c488ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Indice correspondant au 1er janvier 2018\n",
    "premier_jour_2018_idx = np.where(df.index.year == 2018)[0].min()\n",
    "\n",
    "# Indice correspondant au 1er janvier 2019\n",
    "premier_jour_2019_idx = np.where(df.index.year == 2019)[0].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39888435",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "\n",
    "\n",
    "# On récupère les données sous la forme d'un tableau NumPy\n",
    "X_numpy = df.to_numpy()\n",
    "\n",
    "# On sépare les données à échelonner\n",
    "X_numpy_to_scale = X_numpy[:, :-2]\n",
    "\n",
    "# On échelonne ces données\n",
    "scaler = MinMaxScaler(feature_range=(-1.0, 1.0))\n",
    "scaler.fit(X_numpy_to_scale[:premier_jour_2018_idx])\n",
    "X_numpy_scaled = scaler.transform(X_numpy_to_scale)\n",
    "\n",
    "# On concatène les données échelonnées et les variables binaires\n",
    "X_numpy_full = np.c_[X_numpy_scaled, X_numpy[:, -2:]]\n",
    "\n",
    "# On transforme ce tableau NumPy en tenseur PyTorch\n",
    "X = torch.from_numpy(X_numpy_full).to(dtype=torch.float32)\n",
    "\n",
    "# On supprime les variables dont on n'a plus besoin\n",
    "del X_numpy, X_numpy_to_scale, X_numpy_scaled, X_numpy_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cbbb22",
   "metadata": {},
   "source": [
    "## Objets `Dataset` et `Dataloader`\n",
    "\n",
    "Comme on a ici un jeu de données dans un contexte particulier (séries temporelles), on va devoir créer notre propre version de `Dataset`, c'est-à-dire créer notre propre classe héritant de la classe [torch.utils.data.Dataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset).\n",
    "\n",
    "Dans la documentation du jeu de données, il est recommandé d'avoir au moins $72$ heures d'écart entre les données d'entrée et les données de sortie.\n",
    "En effet, il faut prévenir un minimum de temps à l'avance pour changer la future quantité d'électricité à produire.\n",
    "Comme on a rééchantillonné les données horaires en données journalières, l'écart minimum entre le dernier jour de l'entrée et le premier jour de la sortie est donc de $3$ jours.\n",
    "La variable `time_gap` permet de définir l'écart (en nombre de jours) entre le dernier jour de l'entrée et le premier jour de la sortie, et sa valeur par défaut est $3$.\n",
    "\n",
    "Il faut également définir la longueur des séries temporelles en entrée et en sortie.\n",
    "La variable `output_length` détermine le nombre de jours pour lesquels on prédit la consommation électrique.\n",
    "Concernant les sorties, on ne cherche pas à prédire la consommation électrique très en avance non plus.\n",
    "On va donc la prédire pendant les $7$ prochains jours (après le délai défini par `time_gap`).\n",
    "La variable `input_length` détermine le nombre de jours pour lesquels on fournit les données en entrée.\n",
    "Le nombre de jours pourrait être variable : on a le droit d'utiliser toutes les données du passé pour prédire le futur.\n",
    "Cependant, pour réduire la complexité de l'entraînement et faciliter la création de lots d'observations, on va utiliser un nombre fixe de jours, fixé à $30$, c'est-à-dire un mois environ.\n",
    "Une limite évidente de cette approche est qu'on ne modélise pas la saisonnalité annuelle.\n",
    "\n",
    "La fonction `create_train_val_test_splits()` définie ci-dessous permet de créer les jeux d'entraînement, de validation et d'évaluation en fonction des valeurs fournies pour les différents arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3771afc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "def create_train_val_test_splits(\n",
    "    X, train_val_split_idx, val_test_split_idx, input_length=30, output_length=7, time_gap=3\n",
    "):\n",
    "    \"\"\"Crée les jeux d'entraînement, de validation et d'évaluation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    train_val_split_idx : int\n",
    "        Indice séparant les jeux d'entraînement et de validation.\n",
    "    \n",
    "    val_test_split_idx : int\n",
    "        Indice séparant les jeux de validation et d'évaluation.\n",
    "    \n",
    "    input_length : int (default = 30)\n",
    "        Nombre de jours pour les séries temporelles en entrée.\n",
    "    \n",
    "    output_length : int (default = 7)\n",
    "        Nombre de jours à prédire.\n",
    "    \n",
    "    time_gap : int (default = 3)\n",
    "        Nombre de jours de séparation entre le dernier jour de l'entrée\n",
    "        et le premier jour de la sortie.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dataset_train : Dataset\n",
    "        Jeu d'entraînement\n",
    "    \n",
    "    dataset_val : Dataset\n",
    "        Jeu de validation\n",
    "    \n",
    "    dataset_test : Dataset\n",
    "        Jeu d'évaluation\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    class CustomDataset(Dataset):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : Tensor, shape = (n_samples, n_features)\n",
    "            Données.\n",
    "        \n",
    "        dataset : {'training', 'validation', 'test'}\n",
    "            Jeu de données considéré.\n",
    "        \"\"\"\n",
    "        def __init__(self, X, dataset):\n",
    "            if dataset not in ('training', 'validation', 'test'):\n",
    "                raise ValueError(\"'dataset' doit être l'un de 'training', 'validation' ou 'test'.\")\n",
    "            self.X = X\n",
    "            self.dataset = dataset\n",
    "\n",
    "        def __len__(self):\n",
    "            if self.dataset == 'training':\n",
    "                return train_val_split_idx - (input_length + time_gap + output_length) + 1\n",
    "            elif self.dataset == 'validation':\n",
    "                return (val_test_split_idx - (train_val_split_idx + output_length)) // output_length + 1\n",
    "            else:\n",
    "                return (len(X) - (val_test_split_idx + output_length)) // output_length + 1\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            if not (0 <= idx < len(self)):\n",
    "                raise ValueError(\n",
    "                    f\"Indice non valide. La longueur du jeu de données est {len(self)}.\"\n",
    "                )\n",
    "            if self.dataset == 'training':\n",
    "                start_idx = 0\n",
    "                step = 1\n",
    "            elif self.dataset == 'validation':\n",
    "                start_idx = train_val_split_idx - input_length - time_gap\n",
    "                step = output_length\n",
    "            else:\n",
    "                start_idx = val_test_split_idx - input_length - time_gap\n",
    "                step = output_length\n",
    "\n",
    "            start_idx_input = start_idx + idx * step\n",
    "            end_idx_input = start_idx_input + input_length\n",
    "            \n",
    "            start_idx_output = end_idx_input + time_gap\n",
    "            end_idx_output = start_idx_output + output_length\n",
    "\n",
    "            return self.X[start_idx_input:end_idx_input], self.X[start_idx_output:end_idx_output, 0]\n",
    "\n",
    "    return CustomDataset(X, 'training'), CustomDataset(X, 'validation'), CustomDataset(X, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8ce665",
   "metadata": {},
   "source": [
    "On l'exécute pour créer les trois jeux de données, puis on crée les *dataloaders* pour chacun des jeux de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1d3f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_length = 30\n",
    "output_length = 7\n",
    "time_gap = 3\n",
    "\n",
    "dataset_train, dataset_val, dataset_test = create_train_val_test_splits(\n",
    "    X, premier_jour_2018_idx, premier_jour_2019_idx, input_length, output_length, time_gap\n",
    ")\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=32, shuffle=True)\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=52, shuffle=False)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=52, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ee20c4",
   "metadata": {},
   "source": [
    "## Réseau de neurones récurrent\n",
    "\n",
    "Il est enfin temps de créer notre réseau de neurones récurrent ! L'architecture de votre réseau sera l'architecture séquentielle suivante :\n",
    "* Couche LSTM avec `lstm_hidden_size` variables dans l'état caché. On ne garde que le dernier état caché.\n",
    "* Couche linéaire avec `linear_out_features` variables en sortie.\n",
    "* Fonction d'activation ReLU\n",
    "* Couche linéaire avec `output_length` variables en sortie (car on prédit pour les `output_length` prochains jours avec le saut de `time_gap` jours).\n",
    "\n",
    "L'intérêt d'utiliser des paramètres pour ces variables est de pouvoir essayer différentes combinaisons sans avoir besoin de recréer une nouvelle classe à chaque fois.\n",
    "Néanmoins, on donnera des valeurs par défaut aux paramètres : `lstm_hidden_size=256` et `linear_out_features=128`.\n",
    "\n",
    "### Exercice 1\n",
    "\n",
    "Complétez les méthodes `__init__()` et `forward()` de la classe `RecurrentNeuralNetwork` définie ci-dessous. Consultez la documentation de [torch.nn.LSTM](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html) pour comprendre l'entrée attendue et la sortie renvoyée par cette couche.\n",
    "\n",
    "Pour rappel, l'entrée renvoyée par le *dataloader*, c'est-à-dire l'entrée du modèle (l'argument `x` de la méthode `forward()`) est un tenseur de taille $(N, L, H_{in})$ où :\n",
    "* $N$ est la taille du lot (argument `batch_size` du dataloader).\n",
    "* $L$ est la longueur de chaque séquence (c'est-à-dire la variable `input_length` définie ci-dessus).\n",
    "* $H_{in}$ est la dimension à chaque instant, c'est-à-dire le nombre de variables, soit $15$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac0e197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "from torchmetrics import MeanSquaredError\n",
    "\n",
    "\n",
    "class RecurrentNeuralNetwork(L.LightningModule):  # La classe hérite de la classe lightning.LightningModule\n",
    "    def __init__(self, lstm_hidden_size=256, linear_out_features=128):\n",
    "        \"\"\"Constructeur.\n",
    "        \n",
    "        Dans le constructeur, on exécute le constructeur de la clase mère et on définit\n",
    "        toutes les couches et fonctions d'activation de notre réseau de neurones.\n",
    "        \"\"\"\n",
    "        super().__init__()  # Toujours exécuter le constructeur de la classe mère\n",
    "        \n",
    "        ### BEGIN TODO ###\n",
    "\n",
    "        #### END TODO ####\n",
    "        \n",
    "        self.loss = MeanSquaredError()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Implémente la passe avant.\n",
    "        \n",
    "        L'argument x est un tenseur correspondant soit à l'entrée une seule\n",
    "        observation soit aux entrées d'un lot d'observations.\n",
    "        \"\"\"\n",
    "        ### BEGIN TODO ###\n",
    "        # y = \n",
    "        ### END TODO ###\n",
    "        return y\n",
    "    \n",
    "    def step(self, batch):\n",
    "        \"\"\"Effectue une étape.\n",
    "\n",
    "        Une étape consiste à passer d'un lot d'observations (l'argument batch)\n",
    "        à l'évaluation de la fonction de coût pour ce lot d'observations.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch : tuple\n",
    "            Un lot d'observations. Le premier élément du tuple est le lot\n",
    "            des entrées, le second est le lot des labels.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        loss : Tensor\n",
    "            La fonction de coût pour ce lot d'observations.\n",
    "        \"\"\"\n",
    "        X, y = batch  # X correspond aux entrées, y aux sorties attendues\n",
    "        y_pred = self(X)  # Passe avant, qui renvoie les logits\n",
    "        loss = self.loss(y_pred, y)  # Évaluation de la fonction de coût\n",
    "        \n",
    "        # Prédictions dans l'espace original\n",
    "        y_cpu = y.cpu().detach()\n",
    "        y_pred_cpu = y_pred.cpu().detach()\n",
    "        y_rescaled = self.inverse_transform(y_cpu)\n",
    "        y_pred_rescaled = self.inverse_transform(y_pred_cpu)\n",
    "        mse_rescaled = self.loss(y_pred_rescaled, y_rescaled)\n",
    "\n",
    "        return loss, mse_rescaled\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        \"\"\"Effectue une étape d'entraînement.\"\"\"\n",
    "        loss, mse_rescaled = self.step(batch)\n",
    "        self.log(\"loss_train\", loss, on_step=False, on_epoch=True)\n",
    "        self.log(\"mse_train\", mse_rescaled, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        \"\"\"Effectue une étape de validation.\"\"\"\n",
    "        loss, mse_rescaled = self.step(batch)\n",
    "        self.log(\"loss_val\", loss, on_step=False, on_epoch=True)\n",
    "        self.log(\"mse_val\", mse_rescaled, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch):\n",
    "        \"\"\"Effectue une étape d'évaluation.\"\"\"\n",
    "        loss, mse_rescaled = self.step(batch)\n",
    "        self.log(\"loss_test\", loss, on_step=False, on_epoch=True)\n",
    "        self.log(\"mse_test\", mse_rescaled, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "    \n",
    "    def on_train_start(self):\n",
    "        \"\"\"Code exécuté au début de l'entraînement.\"\"\"\n",
    "        string = f\"Version {self.trainer.logger.version}\"\n",
    "        print(f\"{string}\\n{'=' * len(string)}\\n\")\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        \"\"\"Code exécuté à la fin de chaque époque d'entraînement.\"\"\"\n",
    "        metrics = self.trainer.callback_metrics\n",
    "        string = (f\"\"\"\n",
    "            Époque {self.trainer.current_epoch + 1} / {self.trainer.max_epochs}\n",
    "            ------------------------------------------------\n",
    "            |     Jeu      | Fonction de perte |    MSE    |\n",
    "            | ------------ | ----------------- | --------- |\n",
    "            | Entraînement |{metrics['loss_train'].item():^19.5f}|{metrics['mse_train'].item():^11.2f}|\n",
    "            |  Validation  |{metrics['loss_val'].item():^19.5f}|{metrics['mse_val'].item():^11.2f}|\n",
    "            ------------------------------------------------\n",
    "        \"\"\")\n",
    "        string = '\\n'.join([line.strip() for line in string.split('\\n')])\n",
    "        print(string)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Configure l'algorithme d'optimisation à utiliser.\"\"\"\n",
    "        optimizer = torch.optim.Adam(self.parameters())\n",
    "        return optimizer\n",
    "    \n",
    "    @staticmethod\n",
    "    def inverse_transform(x):\n",
    "        \"\"\"Applique la transformation inverse pour la série temporelle à prédire.\n",
    "        \n",
    "        Paramters\n",
    "        ---------\n",
    "        x : Tensor, shape = (output_length,)\n",
    "            Série temporelle échelonnée prédite.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        x_new : Tensor, shape = (output_length,)\n",
    "            Série temporelle prédite dans l'espace original.\n",
    "        \"\"\"\n",
    "        return (\n",
    "            (x - scaler.feature_range[0])\n",
    "            /\n",
    "            (scaler.feature_range[1] - scaler.feature_range[0])\n",
    "            *\n",
    "            (scaler.data_max_[0] - scaler.data_min_[0])\n",
    "        ) + scaler.data_min_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21772f71",
   "metadata": {},
   "source": [
    "### Exercice 2\n",
    "\n",
    "Affichez un résumé de votre réseau de neurones avec les valeurs par défaut. Combien de paramètres entraînables contient-il ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a5f28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b55d7b",
   "metadata": {},
   "source": [
    "**Réponse** : TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a562151c",
   "metadata": {},
   "source": [
    "On va maintenant entraîner le modèle pendant `100` époques en exécutant le code ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab08cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.loggers import CSVLogger\n",
    "from lightning.pytorch.callbacks import TQDMProgressBar\n",
    "\n",
    "\n",
    "model = RecurrentNeuralNetwork()\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=100,\n",
    "    enable_model_summary=False,  # supprimer le résumé du modèle\n",
    "    logger=CSVLogger('.'),  # sauvegarder les résultats dans un fichier CSV\n",
    "    num_sanity_val_steps=0,  # ne pas effectuer d'étape de validation avant l'entraînement\n",
    "    callbacks=[TQDMProgressBar(refresh_rate=0)],  # on supprime la barre de progression\n",
    "    log_every_n_steps=0,  # on ne sauvegarde les résultats qu'à la fin de chaque époque\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    model=model,\n",
    "    train_dataloaders=dataloader_train,\n",
    "    val_dataloaders=dataloader_val\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4499b0f8",
   "metadata": {},
   "source": [
    "### Exercice 3\n",
    "\n",
    "Pour rappel, l'erreur quadratique moyenne est à la fois la fonction de perte (pour entraîner le modèle) et la métrique (pour évaluer le modèle).\n",
    "Cependant, on a normalisé les données pour faciliter l'entraînement du modèle.\n",
    "Pour la métrique, on va *dénormaliser* les prédictions pour les remettre dans l'espace original, puisque c'est celui qui importe en pratique.\n",
    "C'est à cela que sert la méthode statique `inverse_transform()` de la classe `RecurrentNeuralNetwork()`.\n",
    "\n",
    "Visualisez la performance du modèle sur les jeux d'entraînement et de validation grâce à la fonction `plot_loss_mse()` définie ci-dessous. Quel problème remarque-vous ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b8d3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_loss_mse(savedir='.', version=None):\n",
    "    \"\"\"Affiche les courbes de la fonction de perte et d'accuracy.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    savedir : str (default = '.')\n",
    "        Chemin où les résultats sont sauvegardés.\n",
    "        \n",
    "    version : int or None (default = None)\n",
    "        Numéro de la version du modèle.\n",
    "    \"\"\"\n",
    "    # Récupère les résultats sous la forme d'un DataFrame\n",
    "    import os\n",
    "    if version is None:\n",
    "        version = max([\n",
    "            int(folder.split('version_')[1])\n",
    "            for folder in os.listdir(os.path.join(savedir, 'lightning_logs'))\n",
    "            if folder.startswith('version')\n",
    "        ])\n",
    "    df = pd.read_csv(os.path.join(savedir, 'lightning_logs', f'version_{version}', 'metrics.csv'))\n",
    "    df['epoch'] += 1  # On commence à compter à partir de 1\n",
    "\n",
    "    loss_train = df.dropna(subset='loss_train').set_index('epoch')['loss_train']\n",
    "    loss_val = df.dropna(subset='loss_val').set_index('epoch')['loss_val']\n",
    "\n",
    "    mse_train = df.dropna(subset='mse_train').set_index('epoch')['mse_train']\n",
    "    mse_val = df.dropna(subset='mse_val').set_index('epoch')['mse_val']\n",
    "\n",
    "    # Affiche les résultats\n",
    "    plt.figure(figsize=(13, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(loss_train.index, loss_train.to_numpy(), '-', label='Entraînement');\n",
    "    plt.plot(loss_val.index, loss_val.to_numpy(), '-', label='Validation');\n",
    "    plt.xlabel('Époque')\n",
    "    plt.ylabel('Fonction de coût')\n",
    "    plt.yscale('log')\n",
    "    plt.legend();\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(mse_val.index, mse_train.to_numpy(), '-', label='Entraînement');\n",
    "    plt.plot(mse_val.index, mse_val.to_numpy(), '-', label='Validation');\n",
    "    plt.xlabel('Époque')\n",
    "    plt.ylabel('Erreur quadratique moyenne')\n",
    "    plt.yscale('log')\n",
    "    plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8401e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_mse()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fd03d3",
   "metadata": {},
   "source": [
    "**Réponse** : TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57ea69b",
   "metadata": {},
   "source": [
    "### Exercice 4\n",
    "\n",
    "Affichez les prédictions du modèle et l'erreur quadratique moyenne sur les jeux d'entraînement et de validation grâce à la fonction `plot_true_pred()` définie ci-dessous :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ee1f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_true_pred(model, dataset):\n",
    "    \"\"\"Affiche les vraies valeurs et les prédictions sur un jeu de données.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : RecurrentNeuralNetwork\n",
    "        Modèle entraîné.\n",
    "\n",
    "    dataset : Dataset\n",
    "        Jeu de données.\n",
    "    \"\"\"\n",
    "    if dataset.dataset == 'training':\n",
    "        step = 7\n",
    "    else:\n",
    "        step = 1\n",
    "\n",
    "    # Calcule les prédictions\n",
    "    X_ = torch.stack([dataset[i][0] for i in range(0, len(dataset), step)])\n",
    "    y_pred = RecurrentNeuralNetwork.inverse_transform(\n",
    "        model(X_).view(-1)\n",
    "    ).detach().numpy()\n",
    "\n",
    "    # Calcule les vraies valeurs \n",
    "    y_true = RecurrentNeuralNetwork.inverse_transform(\n",
    "        torch.cat([dataset[i][1] for i in range(0, len(dataset), step)])\n",
    "    ).detach().numpy()\n",
    "    \n",
    "    if dataset.dataset == 'training':\n",
    "        index = df.iloc[input_length+time_gap:premier_jour_2018_idx].index[:len(y_true)]\n",
    "    elif dataset.dataset == 'validation':\n",
    "        index = df.iloc[premier_jour_2018_idx:premier_jour_2019_idx].index[:len(y_true)]\n",
    "    else:\n",
    "        index = df.iloc[premier_jour_2019_idx:].index[:len(y_true)]\n",
    "\n",
    "    df_temp = pd.DataFrame([index, y_true, y_pred]).T\n",
    "    df_temp.columns = ['Date', 'Vraies valeurs', 'Prédictions']\n",
    "    df_temp.set_index('Date', inplace=True)\n",
    "    \n",
    "    plt.figure(figsize=(20, 4))\n",
    "    plt.plot(df_temp['Vraies valeurs'], label='Vraies valeurs')\n",
    "    plt.plot(df_temp['Prédictions'], label='Prédictions')\n",
    "    plt.legend()\n",
    "    plt.title(f'Erreur quadratique moyenne = {((y_true - y_pred) ** 2).mean():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38b5fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7014cc",
   "metadata": {},
   "source": [
    "Maintenant que l'on a remarqué que le modèle souffre de surapprentissage, il est temps de proposer une méthode pour l'éviter.\n",
    "Une approche possible est d'effectuer de l'*early stoppping*, c'est-à-dire arrêter l'entraînement du modèle plus tôt.\n",
    "Un critère d'arrêt classique est que la fonction de coût sur le jeu de validation ne diminue plus après $n$ époques, où $n$ est un hyperparamètre à définir.\n",
    "\n",
    "Avec PyTorch Lightning, cette approche se définit dans le `Trainer`, et plus particulièrement grâce à l'argument `callbacks`.\n",
    "On indique à PyTorch Lightning qu'on veut effectuer un arrêt anticipé en ajoutant une instance de [lightning.pytorch.callbacks.early_stopping.EarlyStopping](https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.callbacks.EarlyStopping.html). Dans cet instance, on indique le score à surveiller (argument `monitor`), quel mode utiliser (argument `mode`, `\"min\"` si le score décroît quand le modèle est meilleur, `\"max\"` si le score croît quand le modèle est meilleur) et le nombre de vérifications (c'est-à-dire le nombre d'époques si on effectue une vérification seulement à la fin de chaque époque) sans amélioration (argument `patience`).\n",
    "La patience est importante car il est possible d'avoir quelques époques où le modèle ne progresse plus, puis qu'il se remette à progresser ensuite.\n",
    "\n",
    "Ici, le score à surveiller est la fonction de perte, qui décroît quand le modèle devient meilleur.\n",
    "On utilise la valeur par défaut pour la patience, qui est de 3.\n",
    "Exécutez le code ci-dessous :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f39ff7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "\n",
    "model_early_stopping = RecurrentNeuralNetwork()\n",
    "\n",
    "trainer_early_stopping = L.Trainer(\n",
    "    max_epochs=100,\n",
    "    enable_model_summary=False,  # supprimer le résumé du modèle\n",
    "    logger=CSVLogger('.'),  # sauvegarder les résultats dans un fichier CSV\n",
    "    num_sanity_val_steps=0,  # ne pas effectuer d'étape de validation avant l'entraînement\n",
    "    callbacks=[\n",
    "        TQDMProgressBar(refresh_rate=0),  # supprime la barre de progression\n",
    "        EarlyStopping(monitor=\"loss_val\", mode=\"min\", patience=3)  # effectue de l'early stopping\n",
    "    ],\n",
    "    log_every_n_steps=0,  # on ne sauvegarde les résultats qu'à la fin de chaque époque\n",
    ")\n",
    "\n",
    "trainer_early_stopping.fit(\n",
    "    model=model_early_stopping,\n",
    "    train_dataloaders=dataloader_train,\n",
    "    val_dataloaders=dataloader_val\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63365c9",
   "metadata": {},
   "source": [
    "On remarque que l'entraînement s'arrête bien avant les $100$ époques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7120a45",
   "metadata": {},
   "source": [
    "### Exercice 5\n",
    "\n",
    "Affichez la performance de ce modèle sur les jeux d'entraînement et d'évaluation grâce à la fonction `plot_true_pred()`.\n",
    "Comparez-la à celle du modèle précédent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5399fdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2381fdf",
   "metadata": {},
   "source": [
    "On remarque également que le modèle final, quand l'*early stopping* a eu lieu, correspond à celui de la dernière époque, qui obtient une performance moins bonne que le modèle une autre époque précédente par définition.\n",
    "Par définition, Lightning sauvegarde le modèle à la fin de chaque époque dans le répertoire `version_X/checkpoints`.\n",
    "Il est possible de modifier ce comportement en utilisant à nouveau l'argument `callbacks` de l'instance de `Trainer` grâce à l'outil [lightning.pytorch.callbacks.ModelCheckpoint](https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.callbacks.ModelCheckpoint.html) en lui fournissant quel score surveiller.\n",
    "On utilise le même score que pour l'*early stopping*, c'est-à-dire la fonction de perte sur le jeu de validation.\n",
    "\n",
    "Exécutez le code ci-dessous :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e63132",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "model_early_stopping_best_checkpoint = RecurrentNeuralNetwork()\n",
    "\n",
    "trainer_early_stopping_best_checkpoint = L.Trainer(\n",
    "    max_epochs=100,\n",
    "    enable_model_summary=False,  # supprimer le résumé du modèle\n",
    "    logger=CSVLogger('.'),  # sauvegarder les résultats dans un fichier CSV\n",
    "    num_sanity_val_steps=0,  # ne pas effectuer d'étape de validation avant l'entraînement\n",
    "    callbacks=[\n",
    "        TQDMProgressBar(refresh_rate=0),  # supprime la barre de progression\n",
    "        EarlyStopping(monitor=\"loss_val\", mode=\"min\", patience=3),  # effectue de l'early stopping\n",
    "        ModelCheckpoint(monitor=\"loss_val\")  # sauvegarde le modèle avec la \"loss_val\" la plus faible\n",
    "    ],\n",
    "    log_every_n_steps=0,  # on ne sauvegarde les résultats qu'à la fin de chaque époque\n",
    ")\n",
    "\n",
    "trainer_early_stopping_best_checkpoint.fit(\n",
    "    model=model_early_stopping_best_checkpoint,\n",
    "    train_dataloaders=dataloader_train,\n",
    "    val_dataloaders=dataloader_val\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb36ac7",
   "metadata": {},
   "source": [
    "### Exercice 6\n",
    "\n",
    "Quand l'entraînement est terminé, allez dans le dossier `lightning_logs/version_X/checkpoints` (remplacez `X` par la version correspondant à ce modèle, normalement la dernière s'il s'agit du dernier modèle entraîné) et regardez le nom du fichier.\n",
    "Il indique l'époque et le pas (le pas est le nombre d'itérations, soit le nombre d'époques multiplié par le nombre de lots du jeu d'entraînement) du modèle sauvegardé.\n",
    "Vérifiez que le numéro de l'époque dans le fichier correspond bien au numéro de l'époque avec la plus faible fonction de perte (ou MSE, c'est identique ici) sur le jeu de validation.\n",
    "\n",
    "> **Attention** : Lightning compte les époques à partir de $0$, mais l'affichage effectué compte les époques à partie de $1$ (car c'est plus naturel pour un humain de compter à partir de 1). Il est donc normal que le numéro de l'époque dans le fichier soit inférieur de 1 au numéro de la meilleure époque affiché dans la sortie.\n",
    "\n",
    "Les paramètres entraînables du modèle sont toujours ceux de la dernière époque.\n",
    "On charge les paramètres entraînables sauvegardés, qui donnent une meilleure performance sur le jeu de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5feffc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "# On identifie le numéro de la dernière version\n",
    "version = max([\n",
    "    int(folder.split('version_')[1])\n",
    "    for folder in os.listdir(os.path.join('.', 'lightning_logs'))\n",
    "    if folder.startswith('version')\n",
    "])\n",
    "# Sinon, on donne le numéro de la version\n",
    "# version =\n",
    "\n",
    "# On récupère le chemin du fichier\n",
    "path = f'./lightning_logs/version_{version}/checkpoints'\n",
    "file = os.listdir(path)[0]\n",
    "\n",
    "# On charge les paramètres entraînables sauvegardés\n",
    "model_early_stopping_best_checkpoint = RecurrentNeuralNetwork.load_from_checkpoint(\n",
    "    os.path.join(path, file), weights_only=True, map_location=torch.device(\"cpu\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5fcbc8",
   "metadata": {},
   "source": [
    "### Exercice 7\n",
    "\n",
    "Choisissez le meilleur modèle sur le jeu de validation et évaluez-le sur le jeu d'évaluation.\n",
    "Par curiosité, évaluez également les autres modèles.\n",
    "Est-ce que le meilleur modèle sur le jeu de validation est également le meilleur modèle sur le jeu d'évaluation ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a4462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
