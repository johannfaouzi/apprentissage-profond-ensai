{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Avant de débuter ce TP** :\n",
    "\n",
    "1. **Changez le type d'exécution sur Google Colab** : `Exécution > Modifiez le type d'exécution > T4 GPU`\n",
    "2. **Installez les paquets ci-dessous** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install lightning torchmetrics torchinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Exécutez ce code pour supprimer quelques messages et avertissements éventuellement affichés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger(\"lightning\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"lightning.pytorch.utilities.rank_zero\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"lightning.pytorch.accelerators.cuda\").setLevel(logging.WARNING)\n",
    "logger = logging.getLogger(\"lightning\")\n",
    "logger.propagate = False\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \".*does not have many workers.*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apprentissage profond - TP 1.2\n",
    "\n",
    "Durant la deuxième partie de ce premier TP, vous allez travailler sur un autre jeu de données : [*forest cover types*](https://archive.ics.uci.edu/dataset/31/covertype).\n",
    "L'objectif est de prédire le type d'un arbre de forêt à partir de certaines caractéristiques.\n",
    "Il s'agit d'un problème de **classification**.\n",
    "\n",
    "En utilisant ce que vous avez appris dans le TP précédent, vous allez devoir :\n",
    "\n",
    "* **prétraiter les données**,\n",
    "* **indiquer comment accéder aux données**,\n",
    "* **construire un réseau de neurones**,\n",
    "* **entraîner et évaluer ce réseau de neurones**\n",
    "\n",
    "Nous utiliserons le paquet `scikit-learn` pour télécharger ce jeu de données. Comme d'habitude, on installe les paquets nécessaires qui ne sont pas déjà installés sur Colab :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons (télé)charger ce jeu de données en utilisant la fonction [sklearn.datasets.fetch_covtype](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_covtype.html).\n",
    "En résumé, cette fonction renvoie deux variables :\n",
    "\n",
    "* `X` est une matrice (un tableau NumPy à deux dimensions) de taille $n \\times p$ où $n$ est le nombre d'observations et $p$ est le nombre de variables. Ce sont les données en entrée.\n",
    "* `y` est un vecteur (un tableau NumPy à une dimension) de taille $n$. Ce sont les données en sortie (à prédire)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_covtype\n",
    "\n",
    "X, y = fetch_covtype(data_home='data', return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 1\n",
    "\n",
    "1. Déterminez la taille du jeu de données, c'est-à-dire le nombre d'observations $n$ et le nombre de variables $p$. Vous pouvez utiliser l'attribut [numpy.ndarray.shape](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.shape.html)\n",
    "\n",
    "2. Déterminez le nombre de classes. Est-ce que les classes sont équilibrées ? Vous pouvez utiliser la fonction [numpy.unique](https://numpy.org/doc/stable/reference/generated/numpy.unique.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'observations : 581012\n",
      "Nombre de variables : 54\n"
     ]
    }
   ],
   "source": [
    "print(f\"Nombre d'observations : {X.shape[0]}\")\n",
    "print(f\"Nombre de variables : {X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes : [1 2 3 4 5 6 7]\n",
      "Nombre de classes : 7\n",
      "Distribution des classes : [0.36460521 0.48759922 0.06153746 0.00472796 0.01633873 0.02989095\n",
      " 0.03530048]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "classes, counts = np.unique(y, return_counts=True)\n",
    "\n",
    "print(f\"Classes : {classes}\")\n",
    "print(f\"Nombre de classes : {classes.size}\")\n",
    "print(f\"Distribution des classes : {counts / counts.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Réponse** : Les classes ne sont clairement pas équilibrées : les deux premières classes sont bien plus fréquentes que les cinq autres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 2\n",
    "\n",
    "Séparez le jeu de données en trois :\n",
    "* un jeu d'entraînement avec 100 000 observations,\n",
    "* un jeu de validation avec 100 000 observations,\n",
    "* un jeu d'évaluation (reste).\n",
    "\n",
    "Vous pouvez utiliser la fonction [sklearn.model_selection.train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html).\n",
    "Assurez-vous que la distribution des classes est identique dans les trois sous-jeux de données en utilisant le paramètre `stratify`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, train_size=200_000, stratify=y\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, train_size=100_000,\n",
    "    stratify=y_train_val\n",
    ")\n",
    "\n",
    "del X_train_val, y_train_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 3\n",
    "\n",
    "Convertissez les tableaux NumPy en tenseurs PyTorch. N'oubliez pas de changer le type des données :\n",
    "* les données en entrée (`X`) doivent passer de `numpy.float64` à `torch.float32`,\n",
    "* les données en sortie (`y`) doivent passer de `numpy.int32` à `torch.int64`.\n",
    "\n",
    "Vous pouvez utiliser les méthodes [torch.from_numpy()](https://pytorch.org/docs/stable/generated/torch.from_numpy.html) et [torch.Tensor.to()](https://pytorch.org/docs/stable/generated/torch.Tensor.to.html).\n",
    "\n",
    "> **Remarque** : Pour les tâches de classification, il est nécessaire de fournir une représentation adaptée des classes pour la fonction de coût. La représentation la plus simple pour une tâche de classification multi-classes est d'utiliser les $K$ premiers entiers naturels (en commençant à partir de zéro), c'est-à-dire les entiers $0, \\ldots, K-1$, $K$ étant le nombre de classes. De cette manière, la correspondance entre la dernière couche du réseau de neurones (renvoyant les probabilités ou les logits) et les classes est basée sur les indicies : `probabilité[k]` correspond à la probabilité d'appartenir à la classe $k$ pour chaque $k \\in \\{ 0, \\ldots, K-1 \\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "X_train = torch.from_numpy(X_train).to(dtype=torch.float32)\n",
    "X_val = torch.from_numpy(X_val).to(dtype=torch.float32)\n",
    "X_test = torch.from_numpy(X_test).to(dtype=torch.float32)\n",
    "\n",
    "y_train = torch.from_numpy(y_train - 1).to(dtype=torch.int64)\n",
    "y_val = torch.from_numpy(y_val - 1).to(dtype=torch.int64)\n",
    "y_test = torch.from_numpy(y_test - 1).to(dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 4\n",
    "\n",
    "Créez votre classe `CustomDataset`. Rappel : elle doit hériter de la classe [torch.utils.data.Dataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) et implémenter les trois méthodes suivantes :\n",
    "\n",
    "* `__init__()`: le constructeur définit toutes les informations nécessaires pour les autres méthodes (par exemple les données ou le chemin vers les données, les éventuelles transformations des données, etc.).\n",
    "\n",
    "* `__len__()`: elle renvoie la taille du jeu de données, c'est-à-dire le nombre d'observations.\n",
    "\n",
    "* `__getitem__(idx)`: elle (charge et) renvoie l'observation correspondant à l'indice fourni `idx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        \"\"\"Constructeur.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : Tensor, shape = (n_samples, n_features)\n",
    "            Input data.\n",
    "        \n",
    "        y : Tensor, shape = (n_samples,)\n",
    "            Output data.\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 5\n",
    "\n",
    "Créez des instances des classes `CustomDataset` et `DataLoader` pour chacun des jeux (entraînement, validation et évaluation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "dataloader_train = DataLoader(CustomDataset(X_train, y_train), batch_size=100, shuffle=True)\n",
    "dataloader_val = DataLoader(CustomDataset(X_val, y_val), batch_size=100, shuffle=False)\n",
    "dataloader_test = DataLoader(CustomDataset(X_test, y_test), batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 6\n",
    "\n",
    "La définition des caractéristiques principales du modèle (architecture) et de son entraînement (algorithme d'optimisation, fonction de perte, métrique d'évaluation) se fait dans une même classe.\n",
    "Complétez les méthodes `__init__()`, `forward()` et `configure_optimizers()` de la classe `NeuralNetwork` définie ci-dessous en utilisant les informations fournies dans le texte ci-dessous.\n",
    "\n",
    "#### Architecture\n",
    "\n",
    "L'architecture de votre réseau de neurones est un **perceptron multicouche** avec les caractéristiques suivantes :\n",
    "* *Première couche cachée* : couche linéaire (128 variables en sortie) + fonction d'activation ReLU\n",
    "* *Deuxième couche cachée* : couche linéaire (64 variables en sortie) + fonction d'activation ReLU\n",
    "* *Dernière couche cachée* : couche linéaire (à vous de déterminer la taille de la sortie)\n",
    "\n",
    "Pour rappel, les couches sont initialisées dans le constructeur et la définition de la passe avant se fait dans la méthode `forward()`.\n",
    "Vous êtes encouragés à aller lire la documentation de [torch.nn.Linear()](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html), [torch.nn.ReLU()](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html) et [torch.nn.Sequential()](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html).\n",
    "\n",
    "#### Entraînement\n",
    "\n",
    "Le modèle sera entraîné en utilisant l'entropie croisée comme fonction de perte et Adam avec les valeurs par défaut pour ses hyperparamètres comme algorithme d'optimisation.\n",
    "Vous êtes encouragés à aller lire la documentation de [torch.nn.CrossEntropyLoss()](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) et [torch.optim.Adam()](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html).\n",
    "\n",
    "#### Métrique\n",
    "\n",
    "La performance d'un modèle sera évalué en utilisant la précision (*accuracy*).\n",
    "Vous pouvez utiliser [torchmetrics.Accuracy()](https://lightning.ai/docs/torchmetrics/stable/classification/accuracy.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "\n",
    "class NeuralNetwork(L.LightningModule):  # La classe hérite de la classe lightning.LightningModule\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Constructeur.\n",
    "        \n",
    "        Dans le constructeur, on exécute le constructeur de la clase mère et on définit\n",
    "        toutes les couches et fonctions d'activation de notre réseau de neurones.\n",
    "        \"\"\"\n",
    "        super().__init__()  # Toujours exécuter le constructeur de la classe mère\n",
    "\n",
    "        # Initialisation de la séquence de couches et de fonctions d'activation\n",
    "        self.sequential = torch.nn.Sequential(\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(54, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 7),\n",
    "        )\n",
    "        \n",
    "        self.loss = torch.nn.CrossEntropyLoss()\n",
    "        self.accuracy_train = Accuracy(task=\"multiclass\", num_classes=7)\n",
    "        self.accuracy_val = Accuracy(task=\"multiclass\", num_classes=7)\n",
    "        self.accuracy_test = Accuracy(task=\"multiclass\", num_classes=7)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Implémente la passe avant.\n",
    "        \n",
    "        L'argument x est un tenseur correspondant soit à l'entrée une seule\n",
    "        observation soit aux entrées d'un lot d'observations.\n",
    "        \"\"\"\n",
    "        return self.sequential(x)\n",
    "    \n",
    "    def step(self, batch, dataset):\n",
    "        \"\"\"Effectue une étape.\n",
    "\n",
    "        Une étape consiste à passer d'un lot d'observations (l'argument batch)\n",
    "        à l'évaluation de la fonction de coût pour ce lot d'observations.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch : tuple\n",
    "            Un lot d'observations. Le premier élément du tuple est le lot\n",
    "            des entrées, le second est le lot des labels.\n",
    "            \n",
    "        dataset : {\"training\", \"validation\", \"test\"}\n",
    "            Jeu de données utilisé.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        loss : Tensor, shape = (1,)\n",
    "            La fonction de coût pour ce lot d'observations.\n",
    "        \"\"\"\n",
    "        X, y = batch  # X correspond aux images, y aux classes\n",
    "        logits = self(X)  # Passe avant, qui renvoie les logits\n",
    "        loss = self.loss(logits, y)  # Évaluation de la fonction de perte\n",
    "        y_pred = logits.argmax(1)  # Prédictions du modèle\n",
    "        \n",
    "        if dataset == \"training\":\n",
    "            metric = self.accuracy_train\n",
    "            name = \"train\"\n",
    "            bar_step = True\n",
    "        elif dataset == \"validation\":\n",
    "            metric = self.accuracy_val\n",
    "            name = \"val\"\n",
    "            bar_step = False\n",
    "        else:\n",
    "            metric = self.accuracy_test\n",
    "            name = \"test\"\n",
    "            bar_step = False\n",
    "    \n",
    "        acc = metric(y_pred, y) # Évaluation de la métrique\n",
    "        self.log(f\"loss_{name}\", loss, prog_bar=bar_step, on_step=bar_step, on_epoch=True)\n",
    "        self.log(f\"accuracy_{name}\", acc, prog_bar=bar_step, on_step=bar_step, on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        \"\"\"Effectue une étape d'entraînement.\"\"\"\n",
    "        return self.step(batch, \"training\")\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        \"\"\"Effectue une étape de validation.\"\"\"\n",
    "        return self.step(batch, \"validation\")\n",
    "\n",
    "    def test_step(self, batch):\n",
    "        \"\"\"Effectue une étape d'évaluation.\"\"\"\n",
    "        return self.step(batch, \"test\")\n",
    "    \n",
    "    def on_train_start(self):\n",
    "        \"\"\"Code exécuté au début de l'entraînement.\"\"\"\n",
    "        string = f\"Version {self.trainer.logger.version}\"\n",
    "        print(f\"{string}\\n{'=' * len(string)}\\n\")\n",
    "        \n",
    "    def on_train_epoch_end(self):\n",
    "        \"\"\"Code exécuté à la fin de chaque époque d'entraînement.\"\"\"\n",
    "        metrics = self.trainer.callback_metrics\n",
    "        string = (f\"\"\"\n",
    "            Époque {self.trainer.current_epoch + 1} / {self.trainer.max_epochs}\n",
    "            ------------------------------------------------\n",
    "            |     Jeu      | Fonction de perte | Précision |\n",
    "            | ------------ | ----------------- | --------- |\n",
    "            | Entraînement |{metrics['loss_train'].item():^19.5f}|{metrics['accuracy_train'].item():^11.3%}|\n",
    "            |  Validation  |{metrics['loss_val'].item():^19.5f}|{metrics['accuracy_val'].item():^11.3%}|\n",
    "            ------------------------------------------------\n",
    "        \"\"\")\n",
    "        string = '\\n'.join([line.strip() for line in string.split('\\n')])\n",
    "        print(string)\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Configure l'algorithme d'optimisation à utiliser.\"\"\"\n",
    "        optimizer = torch.optim.Adam(self.parameters())\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va maintenant entraîner le modèle pendant 10 époques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4434d6b7f0414487b3d927bcca523a71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version 0\n",
      "=========\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Époque 1 / 10\n",
      "------------------------------------------------\n",
      "|     Jeu      | Fonction de perte | Précision |\n",
      "| ------------ | ----------------- | --------- |\n",
      "| Entraînement |      1.72563      |  54.282%  |\n",
      "|  Validation  |      1.03241      |  58.800%  |\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Époque 2 / 10\n",
      "------------------------------------------------\n",
      "|     Jeu      | Fonction de perte | Précision |\n",
      "| ------------ | ----------------- | --------- |\n",
      "| Entraînement |      0.92777      |  63.117%  |\n",
      "|  Validation  |      1.06841      |  61.193%  |\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Époque 3 / 10\n",
      "------------------------------------------------\n",
      "|     Jeu      | Fonction de perte | Précision |\n",
      "| ------------ | ----------------- | --------- |\n",
      "| Entraînement |      0.81737      |  65.562%  |\n",
      "|  Validation  |      0.74389      |  68.080%  |\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Époque 4 / 10\n",
      "------------------------------------------------\n",
      "|     Jeu      | Fonction de perte | Précision |\n",
      "| ------------ | ----------------- | --------- |\n",
      "| Entraînement |      0.76652      |  67.171%  |\n",
      "|  Validation  |      0.81834      |  62.048%  |\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Époque 5 / 10\n",
      "------------------------------------------------\n",
      "|     Jeu      | Fonction de perte | Précision |\n",
      "| ------------ | ----------------- | --------- |\n",
      "| Entraînement |      0.73339      |  68.558%  |\n",
      "|  Validation  |      0.71946      |  69.080%  |\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Époque 6 / 10\n",
      "------------------------------------------------\n",
      "|     Jeu      | Fonction de perte | Précision |\n",
      "| ------------ | ----------------- | --------- |\n",
      "| Entraînement |      0.69665      |  69.947%  |\n",
      "|  Validation  |      0.66904      |  71.432%  |\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Époque 7 / 10\n",
      "------------------------------------------------\n",
      "|     Jeu      | Fonction de perte | Précision |\n",
      "| ------------ | ----------------- | --------- |\n",
      "| Entraînement |      0.68231      |  70.574%  |\n",
      "|  Validation  |      0.64631      |  72.297%  |\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Époque 8 / 10\n",
      "------------------------------------------------\n",
      "|     Jeu      | Fonction de perte | Précision |\n",
      "| ------------ | ----------------- | --------- |\n",
      "| Entraînement |      0.66348      |  71.410%  |\n",
      "|  Validation  |      0.64313      |  72.243%  |\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Époque 9 / 10\n",
      "------------------------------------------------\n",
      "|     Jeu      | Fonction de perte | Précision |\n",
      "| ------------ | ----------------- | --------- |\n",
      "| Entraînement |      0.65126      |  71.718%  |\n",
      "|  Validation  |      0.62182      |  73.648%  |\n",
      "------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Époque 10 / 10\n",
      "------------------------------------------------\n",
      "|     Jeu      | Fonction de perte | Précision |\n",
      "| ------------ | ----------------- | --------- |\n",
      "| Entraînement |      0.64433      |  72.232%  |\n",
      "|  Validation  |      0.62603      |  72.977%  |\n",
      "------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch.callbacks import TQDMProgressBar\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "\n",
    "\n",
    "model = NeuralNetwork()\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=10,\n",
    "    enable_model_summary=False,  # supprimer le résumé du modèle\n",
    "    logger=CSVLogger('.'),  # sauvegarder les résultats dans un fichier CSV\n",
    "    num_sanity_val_steps=0,  # ne pas effectuer d'étape de validation avant l'entraînement\n",
    "    callbacks=[TQDMProgressBar(refresh_rate=100)]  # mettre à jour la barre de progression tous les 100 lots\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    model=model,\n",
    "    train_dataloaders=dataloader_train,\n",
    "    val_dataloaders=dataloader_val\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 7\n",
    "\n",
    "Est-ce que la précision (*accuracy*) est une métrique appropriée ici ?\n",
    "Quelle métrique serait davantage pertinente ?\n",
    "Y a-t-il également des modifications à faire pour potentiellement améliorer l'entraînement ?\n",
    "Regardez la documentation de [torchmetrics.Accuracy()](https://lightning.ai/docs/torchmetrics/stable/classification/accuracy.html) et de [torch.nn.CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) et faîtes les modifications nécessaires dans la méthode `forward()`.\n",
    "Vous pouvez utiliser la fonction [torch.bincount()](https://pytorch.org/docs/stable/generated/torch.bincount.html) pour compter le nombre d'observations pour les différentes classes.\n",
    "\n",
    "> **Remarque** : La précision équilibrée (*balanced accuracy*) nécessite de connaître la distribution des classes pour connaître les poids des classes. La distribution des classes étant connue à la fin (quand on a parcouru tout le jeu de données), il n'est donc pas possible de calculer les scores de précision équilibrée sur tous les lots intermédiaires. La bonne approche est de *mettre à jour* la métrique (avec la méthode `update()`) à chaque étape (*step*), puis de calculer la précision équilibrée à la fin de l'époque (avec la méthode `compute()`) et enfin de réinitialiser les informations sauvegardées sous le capot pour calculer la précision équilibrée (avec la méthode `reset()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "from torch import nn\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "\n",
    "class NeuralNetworkUpdated(L.LightningModule):  # La classe hérite de la classe lightning.LightningModule\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Constructeur.\n",
    "        \n",
    "        Dans le constructeur, on exécute le constructeur de la clase mère et on définit\n",
    "        toutes les couches et fonctions d'activation de notre réseau de neurones.\n",
    "        \"\"\"\n",
    "        super().__init__()  # Toujours exécuter le constructeur de la classe mère\n",
    "\n",
    "        # Initialisation de la séquence de couches et de fonctions d'activation\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(54, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 7),\n",
    "        )\n",
    "\n",
    "        ### BEGIN TODO ###\n",
    "        class_weights = len(y_train) / torch.bincount(y_train)\n",
    "        self.loss = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "        self.bal_acc_train = Accuracy(task=\"multiclass\", average='macro', num_classes=7)\n",
    "        self.bal_acc_val = Accuracy(task=\"multiclass\", average='macro', num_classes=7)\n",
    "        self.bal_acc_test = Accuracy(task=\"multiclass\", average='macro', num_classes=7)\n",
    "        #### END TODO ####\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Implémente la passe avant.\n",
    "        \n",
    "        L'argument x est un tenseur correspondant soit à l'entrée une seule\n",
    "        observation soit aux entrées d'un lot d'observations.\n",
    "        \"\"\"\n",
    "        return self.sequential(x)\n",
    "    \n",
    "    def step(self, batch, dataset):\n",
    "        \"\"\"Effectue une étape.\n",
    "\n",
    "        Une étape consiste à passer d'un lot d'observations (l'argument batch)\n",
    "        à l'évaluation de la fonction de coût pour ce lot d'observations.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch : tuple\n",
    "            Un lot d'observations. Le premier élément du tuple est le lot\n",
    "            des entrées, le second est le lot des labels.\n",
    " \n",
    "        dataset : {\"training\", \"validation\", \"test\"}\n",
    "            Jeu de données utilisé.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        loss : Tensor, shape = (1,)\n",
    "            La fonction de coût pour ce lot d'observations.\n",
    "        \"\"\"\n",
    "        X, y = batch  # X correspond aux images, y aux classes\n",
    "        logits = self(X)  # Passe avant, qui renvoie les logits\n",
    "        loss = self.loss(logits, y)  # Évaluation de la fonction de perte\n",
    "        y_pred = logits.argmax(1)  # Prédictions du modèle\n",
    "        \n",
    "        if dataset == \"training\":\n",
    "            metric = self.bal_acc_train\n",
    "            name = \"train\"\n",
    "            bar_step = True\n",
    "        elif dataset == \"validation\":\n",
    "            metric = self.bal_acc_val\n",
    "            name = \"val\"\n",
    "            bar_step = False\n",
    "        else:\n",
    "            metric = self.bal_acc_test\n",
    "            name = \"test\"\n",
    "            bar_step = False\n",
    "    \n",
    "        acc = metric(y_pred, y) # Évaluation de la métrique\n",
    "        self.log(f\"weighted_loss_{name}\", loss, prog_bar=bar_step, on_step=bar_step, on_epoch=True)\n",
    "        self.log(f\"balanced_accuracy_{name}\", acc, prog_bar=bar_step, on_step=bar_step, on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        \"\"\"Effectue une étape d'entraînement.\"\"\"\n",
    "        return self.step(batch, \"training\")\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        \"\"\"Effectue une étape de validation.\"\"\"\n",
    "        return self.step(batch, \"validation\")\n",
    "\n",
    "    def test_step(self, batch):\n",
    "        \"\"\"Effectue une étape d'évaluation.\"\"\"\n",
    "        return self.step(batch, \"test\")\n",
    "    \n",
    "    def on_train_start(self):\n",
    "        \"\"\"Code exécuté au début de l'entraînement.\"\"\"\n",
    "        string = f\"Version {self.trainer.logger.version}\"\n",
    "        print(f\"{string}\\n{'=' * len(string)}\\n\")\n",
    "        \n",
    "    def on_train_epoch_end(self):\n",
    "        \"\"\"Code exécuté à la fin de chaque époque d'entraînement.\"\"\"\n",
    "        self.log('balanced_accuracy_train', self.bal_acc_train.compute())\n",
    "        self.bal_acc_train.reset()\n",
    "        \n",
    "        metrics = self.trainer.callback_metrics\n",
    "        weighted_loss_train = metrics['weighted_loss_train'].item()\n",
    "        weighted_loss_val = metrics['weighted_loss_val'].item()\n",
    "        bal_acc_train = metrics['balanced_accuracy_train'].item()\n",
    "        bal_acc_val = metrics['balanced_accuracy_val'].item()\n",
    "        \n",
    "        string = (f\"\"\"\n",
    "            Époque {self.trainer.current_epoch + 1} / {self.trainer.max_epochs}\n",
    "            --------------------------------------------------\n",
    "            |     Jeu      | Fonction de perte | B. accuracy |\n",
    "            | ------------ | ----------------- | ----------- |\n",
    "            | Entraînement |{weighted_loss_train:^19.5f}|{bal_acc_train:^13.3%}|\n",
    "            |  Validation  |{weighted_loss_val:^19.5f}|{bal_acc_val:^13.3%}|\n",
    "            --------------------------------------------------\n",
    "        \"\"\")\n",
    "        string = '\\n'.join([line.strip() for line in string.split('\\n')])\n",
    "        print(string)\n",
    "        \n",
    "    def on_validation_epoch_end(self):\n",
    "        self.log('balanced_accuracy_val', self.bal_acc_val.compute())\n",
    "        self.bal_acc_val.reset()\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        self.log('balanced_accuracy_test', self.bal_acc_test.compute())\n",
    "        self.bal_acc_test.reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Configure l'algorithme d'optimisation à utiliser.\"\"\"\n",
    "        optimizer = torch.optim.Adam(self.parameters())\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On entraîne un nouveau modèle pendant $10$ époques également."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "172293780d034413a27b0c9697398936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version 1\n",
      "=========\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Époque 1 / 10\n",
      "--------------------------------------------------\n",
      "|     Jeu      | Fonction de perte | B. accuracy |\n",
      "| ------------ | ----------------- | ----------- |\n",
      "| Entraînement |      2.24550      |   37.490%   |\n",
      "|  Validation  |      1.20830      |   46.541%   |\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Époque 2 / 10\n",
      "--------------------------------------------------\n",
      "|     Jeu      | Fonction de perte | B. accuracy |\n",
      "| ------------ | ----------------- | ----------- |\n",
      "| Entraînement |      1.20390      |   51.988%   |\n",
      "|  Validation  |      1.01184      |   59.282%   |\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Époque 3 / 10\n",
      "--------------------------------------------------\n",
      "|     Jeu      | Fonction de perte | B. accuracy |\n",
      "| ------------ | ----------------- | ----------- |\n",
      "| Entraînement |      1.00218      |   58.650%   |\n",
      "|  Validation  |      1.05441      |   52.890%   |\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Époque 4 / 10\n",
      "--------------------------------------------------\n",
      "|     Jeu      | Fonction de perte | B. accuracy |\n",
      "| ------------ | ----------------- | ----------- |\n",
      "| Entraînement |      0.91867      |   62.229%   |\n",
      "|  Validation  |      0.82938      |   65.649%   |\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Époque 5 / 10\n",
      "--------------------------------------------------\n",
      "|     Jeu      | Fonction de perte | B. accuracy |\n",
      "| ------------ | ----------------- | ----------- |\n",
      "| Entraînement |      0.85235      |   64.623%   |\n",
      "|  Validation  |      0.91706      |   62.751%   |\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Époque 6 / 10\n",
      "--------------------------------------------------\n",
      "|     Jeu      | Fonction de perte | B. accuracy |\n",
      "| ------------ | ----------------- | ----------- |\n",
      "| Entraînement |      0.81540      |   66.532%   |\n",
      "|  Validation  |      0.76737      |   67.846%   |\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Époque 7 / 10\n",
      "--------------------------------------------------\n",
      "|     Jeu      | Fonction de perte | B. accuracy |\n",
      "| ------------ | ----------------- | ----------- |\n",
      "| Entraînement |      0.80634      |   67.125%   |\n",
      "|  Validation  |      0.78494      |   67.467%   |\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Époque 8 / 10\n",
      "--------------------------------------------------\n",
      "|     Jeu      | Fonction de perte | B. accuracy |\n",
      "| ------------ | ----------------- | ----------- |\n",
      "| Entraînement |      0.76593      |   69.054%   |\n",
      "|  Validation  |      0.73584      |   69.645%   |\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Époque 9 / 10\n",
      "--------------------------------------------------\n",
      "|     Jeu      | Fonction de perte | B. accuracy |\n",
      "| ------------ | ----------------- | ----------- |\n",
      "| Entraînement |      0.76210      |   68.906%   |\n",
      "|  Validation  |      0.75115      |   68.014%   |\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Époque 10 / 10\n",
      "--------------------------------------------------\n",
      "|     Jeu      | Fonction de perte | B. accuracy |\n",
      "| ------------ | ----------------- | ----------- |\n",
      "| Entraînement |      0.73274      |   70.467%   |\n",
      "|  Validation  |      0.70680      |   70.723%   |\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_updated = NeuralNetworkUpdated()\n",
    "\n",
    "trainer_updated = L.Trainer(\n",
    "    max_epochs=10,\n",
    "    enable_model_summary=False,  # supprimer le résumé du modèle\n",
    "    logger=CSVLogger('.'),  # sauvegarder les résultats dans un fichier CSV\n",
    "    num_sanity_val_steps=0,  # ne pas effectuer d'étape de validation avant l'entraînement\n",
    "    callbacks=[TQDMProgressBar(refresh_rate=100)]  # mettre à jour la barre de progression tous les 100 lots\n",
    ")\n",
    "\n",
    "trainer_updated.fit(\n",
    "    model=model_updated,\n",
    "    train_dataloaders=dataloader_train,\n",
    "    val_dataloaders=dataloader_val\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 8\n",
    "\n",
    "Faîtes les modifications que vous souhaitez, par exemple au niveau de l'architecture ou de la procédure d'entraînement, et entraînez vos nouveaux modèles.\n",
    "**Gardez vos modèles précédents** et créez de nouveaux objets à chaque fois, afin de pouvoir comparer ces différents modèles ensuite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 9\n",
    "\n",
    "Quand vous avez fini toutes vos expériences, il est temps de choisir le meilleur modèle sur le jeu de validation. \n",
    "Évaluez sa performance sur le jeu d'évaluation.\n",
    "Par curiosité, évaluez également la performance des autres modèles sur le jeu d'évaluation.\n",
    "Vous êtes encouragés à aller lire la [documentation](https://lightning.ai/docs/torchmetrics/stable/pages/overview.html) de `torchmetrics` pour découvrir le principe d'utilisation des métriques implémentées dans ce paquet.\n",
    "\n",
    "> **Remarque** : La première classe utilise la précision (*accuracy*) comme métrique d'évaluation, tandis que la deuxième classe utilise la précision équilibrée (*balanced accuracy*). Il n'est évidemment pas pertinent de comparer des scores de précision avec des scores de précision équilibrée. De même, la fonction de perte est maintenant pondérée dans la deuxième classe. Il n'est donc pas possible d'utiliser les méthodes `validate()` et `test()` pour comparer des modèles définis par des classes différentes si les classes utilisent différents critères d'évaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a63b39a441e4585859016602c4647bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       accuracy_val        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7297700047492981     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         loss_val          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6260322332382202     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      accuracy_val       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7297700047492981    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        loss_val         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6260322332382202    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'loss_val': 0.6260322332382202, 'accuracy_val': 0.7297700047492981}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.validate(model, dataloader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e20a842541cc4bbaae1a8038e136e6dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   balanced_accuracy_val   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7072253227233887     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     weighted_loss_val     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7067967057228088     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m  balanced_accuracy_val  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7072253227233887    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    weighted_loss_val    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7067967057228088    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'weighted_loss_val': 0.7067967057228088,\n",
       "  'balanced_accuracy_val': 0.7072253227233887}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_updated.validate(model_updated, dataloader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy sur le jeu de validation\n",
      "------------------------------------------\n",
      "Modèle initial = 57.69%\n",
      "Nouveau modèle = 70.72%\n"
     ]
    }
   ],
   "source": [
    "bal_accuracy_1 = Accuracy(task=\"multiclass\", average='macro', num_classes=7)\n",
    "bal_accuracy_2 = Accuracy(task=\"multiclass\", average='macro', num_classes=7)\n",
    "\n",
    "for batch in dataloader_val:\n",
    "    X, y = batch\n",
    "\n",
    "    y_pred_1 = model(X).argmax(1)\n",
    "    y_pred_2 = model_updated(X).argmax(1)\n",
    "    \n",
    "    bal_accuracy_1(y_pred_1, y)\n",
    "    bal_accuracy_2(y_pred_2, y)\n",
    "\n",
    "print(f\"Balanced accuracy sur le jeu de validation\\n{'-' * 42}\")\n",
    "print(f\"Modèle initial = {bal_accuracy_1.compute().item():.2%}\")\n",
    "print(f\"Nouveau modèle = {bal_accuracy_2.compute().item():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b13248a19454b16bd373278ccb7fe42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       accuracy_test       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7294599413871765     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         loss_test         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6288752555847168     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      accuracy_test      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7294599413871765    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        loss_test        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6288752555847168    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'loss_test': 0.6288752555847168, 'accuracy_test': 0.7294599413871765}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, dataloader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe75ec833e4b4463b58bc56166ea2008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  balanced_accuracy_test   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7049559354782104     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    weighted_loss_test     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7139744758605957     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m balanced_accuracy_test  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7049559354782104    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   weighted_loss_test    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7139744758605957    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'weighted_loss_test': 0.7139744758605957,\n",
       "  'balanced_accuracy_test': 0.7049559354782104}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_updated.test(model_updated, dataloader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy sur le jeu d'évaluation\n",
      "-----------------------------------------\n",
      "Modèle initial = 57.47%\n",
      "Nouveau modèle = 70.50%\n"
     ]
    }
   ],
   "source": [
    "bal_accuracy_1 = Accuracy(task=\"multiclass\", average='macro', num_classes=7)\n",
    "bal_accuracy_2 = Accuracy(task=\"multiclass\", average='macro', num_classes=7)\n",
    "\n",
    "for batch in dataloader_test:\n",
    "    X, y = batch\n",
    "\n",
    "    y_pred_1 = model(X).argmax(1)\n",
    "    y_pred_2 = model_updated(X).argmax(1)\n",
    "    \n",
    "    bal_accuracy_1(y_pred_1, y)\n",
    "    bal_accuracy_2(y_pred_2, y)\n",
    "\n",
    "print(f\"Balanced accuracy sur le jeu d'évaluation\\n{'-' * 41}\")\n",
    "print(f\"Modèle initial = {bal_accuracy_1.compute().item():.2%}\")\n",
    "print(f\"Nouveau modèle = {bal_accuracy_2.compute().item():.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
