{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Avant de débuter ce TP** :\n",
    "\n",
    "1. **Changez le type d'exécution sur Google Colab** : `Exécution > Modifiez le type d'exécution > T4 GPU`\n",
    "2. **Installez les paquets ci-dessous** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install lightning torchmetrics torchinfo pyconll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Exécutez ce code pour supprimer quelques messages et avertissements éventuellement affichés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger(\"lightning\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"lightning.pytorch.utilities.rank_zero\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"lightning.pytorch.accelerators.cuda\").setLevel(logging.WARNING)\n",
    "logger = logging.getLogger(\"lightning\")\n",
    "logger.propagate = False\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \".*does not have many workers.*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice de grammaire par réseau de neurones récurrent\n",
    "\n",
    "Dans ce notebook, nous allons travailler sur le jeu de données [noun verb](https://github.com/google-research-datasets/noun-verb).\n",
    "Ce jeu de données contient des phrases en anglais naturelles où il peut y avoir une certaine ambiguïté sur le rôle d'un mot, c'est-à-dire de savoir s'il s'agit d'un nom ou d'un verbe.\n",
    "\n",
    "Vous trouverez ci-dessous quelques observations de ce jeu de données illustrant la tâche. Le mot en gras est le mot à classer et le mot en italique après la phrase indique la bonne réponse :\n",
    "\n",
    "> Certain insects can damage plumerias, such as mites, **flies**, or aphids. *NOUN*\n",
    "\n",
    "> **Mark** which area you want to distress. *VERB*\n",
    "\n",
    "Par exemple, le mot **flies** peut correspondre à la troisième personne au singulier du verbe *fly* (par exemple *time flies by so fast*), mais également au pluriel du nom *fly* (mouche).\n",
    "De même, le mot **mark** peut correspondre au verbe *mark* (marquer) ou au nom *mark* (marque).\n",
    "\n",
    "Le tâche est donc une classification binaire car il n'y a que deux classes possibles : *nom* ou *verbe*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Télé)chargement du jeu de données\n",
    "\n",
    "Le jeu de données est déjà séparé en trois jeux d'entraînement, de validation et d'évaluation.\n",
    "Les fichiers correspondants (`train.conll`, `dev.conll` and `test.conll`) sont disponibles sur ce [dépôt GitHub](https://github.com/google-research-datasets/noun-verb).\n",
    "La fonction `load_dataset` permet de charger (et télécharger si besoin) les trois jeux de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path='data'):\n",
    "    \"\"\"Load the noun verb dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        Chemin du répertoire.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train : Conll\n",
    "        Jeu d'entraînement.\n",
    "\n",
    "    validation : Conll\n",
    "        Jeu de validation.\n",
    "\n",
    "    test : Conll\n",
    "        Jeu d'évaluation.\n",
    "\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import pyconll\n",
    "    from urllib.request import urlretrieve\n",
    "\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    files = ('train.conll', 'dev.conll', 'test.conll')\n",
    "\n",
    "    # Downloads the files if necessary\n",
    "    for file in files:\n",
    "        if not os.path.isfile(os.path.join(path, file)):\n",
    "            url = f'https://raw.githubusercontent.com/google-research-datasets/noun-verb/master/{file}'\n",
    "            urlretrieve(url, os.path.join(path, file))\n",
    "\n",
    "    return (pyconll.load_from_file(os.path.join(path, file)) for file in files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il suffit d'exécuter la fonction pour (télé)charger les trois jeux de données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validation, test = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisons la tâche d'apprentissage automatique.\n",
    "La fonction `print_sample` affiche l'observation d'un jeu de données correspondant à l'indice fourni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sample(dataset, idx):\n",
    "    \"\"\"Affiche une observation d'un jeu de données.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : Conll\n",
    "        Dataset.\n",
    "\n",
    "    idx : int\n",
    "        Indice de l'observation à afficher.\n",
    "\n",
    "    \"\"\"\n",
    "    import re\n",
    "\n",
    "    if not 0 <= idx < len(dataset):\n",
    "        raise ValueError(\"Invalid index.\")\n",
    "\n",
    "    label = None\n",
    "    index = None\n",
    "\n",
    "    for i, token in enumerate(dataset[idx]):\n",
    "        if len(token.feats):\n",
    "            if label is not None:\n",
    "                raise ValueError(\"Invalid sample. Try another index.\")\n",
    "            label = next(iter(token.feats['POS']))\n",
    "            index = i\n",
    "\n",
    "    if label is None:\n",
    "        raise ValueError(\"Invalid sample. Try another index.\")\n",
    "\n",
    "    sentence = ' '.join([token.form for token in dataset[idx]])\n",
    "\n",
    "    # Punctuation formatting\n",
    "    for char in \",:;.?!)'\":\n",
    "        pattern = f' *\\\\{char}' if char in '.?)' else f' *{char}'\n",
    "        sentence = re.sub(pattern, char, sentence)\n",
    "\n",
    "    for char in \"(`\":\n",
    "        pattern = f'\\\\{char} *' if char in '(' else f'{char} *'\n",
    "        sentence = re.sub(pattern, char, sentence)\n",
    "\n",
    "    res = 'Sentence' + '\\n' + '=' * 8 + '\\n'\n",
    "    res += sentence\n",
    "    res += '\\n\\n' + 'Word' + '\\n' + \"=\" * 4 + '\\n'\n",
    "    res += dataset[idx][index].form + f' (at position {index})'\n",
    "    res += '\\n\\n' + 'Label' + '\\n' + \"=\" * 5 + '\\n'\n",
    "    res += label\n",
    "\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 1\n",
    "\n",
    "Exécutez cette fonction pour afficher quelques observations des jeux d'entraînement, de validation et d'évaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Représentations vectorielles de mots\n",
    "\n",
    "La tâche à effectuer relève du **traitement automatique des langues** car les données en entrée sont des phrases (en anglais).\n",
    "Une phrase est une séquence de **tokens**.\n",
    "Un token est une unité d'une langue.\n",
    "Par exemple, les mots sont des tokens, mais les signes de ponctuation (virgule, point d'exclamation, etc.) sont également des tokens.\n",
    "Cependant, il n'est pas pratique de travailler directement avec des tokens : les modèles d'apprentissage automatique sont des fonctions mathématiques dont les entrées sont *numériques*.\n",
    "Il est néamoins possible de **transformer les tokens en vecteurs numériques**.\n",
    "De telles représentations sont connues en anglais sous le terme *embeddings* et nous utiliserons le terme **représentations vectorielles** en français.\n",
    "\n",
    "Une approche triviale serait de transformer chaque mot en un vecteur ne contenant que des zéros à part pour un élément dont la valeur serait 1.\n",
    "Cette approche est connue en apprentissage automatique sous le terme **encodage *one-hot*** et peut être utilisée pour transformer une variable catégorielle en plusieurs variables binaires.\n",
    "Cependant, cette approche a de nombreux inconvénients :\n",
    "\n",
    "* Il y a de nombreux mots différents dans une langue, par exemple des centaines de milliers en anglais et en français.\n",
    "* Les données ont été transformées, mais aucune information pertinente n'a été extraite dans cete représentation.\n",
    "\n",
    "Une approche plus utile est de **transformer un mot en un vecteur numérique dense de petite dimension**.\n",
    "Ici, nous n'allons pas apprendre nous-mêmes ces représentations, mais nous allons utiliser des représentations disponibles publiquement qui ont été apprises sur des jeux de données très grands.\n",
    "\n",
    "Une collection de telles représentations est connue sous le nom de [GloVe](https://nlp.stanford.edu/projects/glove/) (pour *Global Vectors for Word Representation*).\n",
    "Il existe plusieurs versions de ces représentations qui dépendent des jeux de données sur lesquels ces modèles ont été entraînés et de la taille des représentations.\n",
    "Nous allons utiliser la première version de GloVe, qui a été entraîné sur Wikipedia et sur des articles de presse.\n",
    "Il existe quatre versions pour les représentations avec des dimensions différentes : $50$, $100$, $200$ et $300$.\n",
    "\n",
    "La commande ci-dessous permet de télécharger l'archive contenant les représentations dans les quatre différentes tailles de dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd data && wget https://nlp.stanford.edu/data/glove.6B.zip && unzip glove.6B.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons utiliser les représentations les plus petites, c'est-à-dire en dimension $50$. **En résumé, nous allons transformer chaque token un vecteur numérique dense de dimension 50**.\n",
    "\n",
    "Pour les tokens qui ne font pas partie du vocabulaire du jeu d'entraînement, on va créer un token spécifique, appelé `out_of_vocabulary`, que l'on va calculer comme le vecteur moyen de toutes les représentations.\n",
    "\n",
    "La fonction `load_embeddings()` charge les données dans un dictionnaire et calcule la représentation moyenne pour le token `out_of_vocabulary`.\n",
    "Chaque clé du dictionnaire est un token et sa valeur est la représentation vectorielle de ce token. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def load_embeddings(path='data'):\n",
    "    \"\"\"Charge les représentations vectorielles GloVe 50d.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        Chemin du le répertoire.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    embeddings : dict\n",
    "        Représentations vectorielles GloVe 50d.\n",
    "\n",
    "    \"\"\"\n",
    "    import os\n",
    "\n",
    "    # Download the file if necessary\n",
    "    if not os.path.isfile(os.path.join(path, 'glove.6B.50d.txt')):\n",
    "        from urllib.request import urlretrieve\n",
    "\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        url = (\n",
    "            'https://media.githubusercontent.com/media/johannfaouzi/'\n",
    "            'apprentissage-profond-ensai/main/data/glove/glove.6B.50d.txt'\n",
    "        )\n",
    "        urlretrieve(url, os.path.join(path, 'glove.6B.50d.txt'))\n",
    "\n",
    "    # Save the results in a dictionary\n",
    "    embeddings = {}\n",
    "\n",
    "    # Get the embedding for each token in the file\n",
    "    mean = torch.zeros(50, dtype=torch.float32)\n",
    "    with open(os.path.join(path, 'glove.6B.50d.txt'), 'r') as file:\n",
    "        for line in file.readlines():\n",
    "            split = line.strip().split(' ')\n",
    "            token = split[0]\n",
    "            value = torch.from_numpy(np.array(split[1:], dtype=np.float32))\n",
    "            embeddings[token] = value\n",
    "            mean += value\n",
    "\n",
    "    # Define the mean embedding for out-of-vocabulary token\n",
    "    embeddings['out_of_vocabulary'] = mean / len(embeddings)\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On exécute cette fonction pour (télé)charger ces représentations vectorielles de mots anglais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = load_embeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 2\n",
    "\n",
    "Affichez les représentations vectorielles de quelques mots anglais courants.\n",
    "\n",
    "> **Remarque** : Tous les mots dans le dictionnaire sont en minuscules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 3\n",
    "\n",
    "Les représentations vectorielles apprises sont connues pour avoir certaines structures linéaires.\n",
    "\n",
    "* Calculez la représentation vectorielle `king + (woman - man)` et comparez-la à la représentation vectorielle de `queen`.\n",
    "* Calculez la représentation vectorielle `strong + (lighter - light)` et comparez-la à la représentation vectorielle de `lighter`.\n",
    "\n",
    "Vous pouvez utiliser la fonction *similarité cosinus* pour déterminer la similitude entre deux vecteurs. La similarité cosinus est définie par :\n",
    "$$\n",
    "    \\cos(x, y) = \\frac{x^\\top y}{\\Vert x \\Vert \\Vert y \\Vert}\n",
    "$$\n",
    "Ses valeurs sont comprises dans l'intervalle $[-1, 1]$. Plus sa valeur est élevée, plus les vecteurs sont similaires.\n",
    "La fonction `cosine_similarity` définie ci-dessous calcule la similarité cosinus entre deux tenseurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(x, y):\n",
    "    \"\"\"Calcule la similarité cosinus entre deux tenseurs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x, y : Tensor, shape = (embedding_size,)\n",
    "        Les deux tenseurs à comparer.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        La similarité cosinus entre les deux tenseurs.\n",
    "    \"\"\"\n",
    "    return ((x @ y) / ((x @ x) * (y @y)) ** 0.5).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prétraitement des données\n",
    "\n",
    "Maintenant qu'on a des représentations vectorielles pour les tokens et une meilleure compréhension des données, il est temps de prétraiter ces données.\n",
    "Pour chaque observation, on va :\n",
    "* transformer la séquence de tokens en une séquence de tenseurs,\n",
    "* récupérer le label du token à classer, et\n",
    "* récupérer l'indice du token à classer.\n",
    "\n",
    "La fonction `preprocess_dataset` effectue ce traitement sur le jeu de données fourni en entrée et renvoie ces trois variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(dataset):\n",
    "    \"\"\"Prétraite un jeu de données.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : Conll\n",
    "        Jeu de données.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : list[Tensors]\n",
    "        Phrases prétraitées.\n",
    "\n",
    "    y : Tensor\n",
    "        Labels rétraités.\n",
    "\n",
    "    index : Tensor\n",
    "        Indices des tokens à prédire.\n",
    "    \"\"\"\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "    index = []\n",
    "\n",
    "    label_mapping = {'NON-VERB': 0, 'VERB': 1}\n",
    "\n",
    "    for sentence in dataset:\n",
    "\n",
    "        embedded_sentence = []\n",
    "        label = None\n",
    "        idx = None\n",
    "\n",
    "        for i, token in enumerate(sentence):\n",
    "\n",
    "            # Get the token in lower cases\n",
    "            token_lower = token.form.lower()\n",
    "\n",
    "            # Get the embedding of the token\n",
    "            if token_lower in embeddings.keys():\n",
    "                embedded_sentence.append(embeddings[token_lower].reshape(1, -1))\n",
    "            else:\n",
    "                embedded_sentence.append(embeddings['out_of_vocabulary'].reshape(1, -1))\n",
    "\n",
    "            # Get the label (if any)\n",
    "            if len(token.feats):\n",
    "                if label is not None:\n",
    "                    raise ValueError(\"Two annotated tokens in a single sentence.\")\n",
    "                label = label_mapping[next(iter(token.feats['POS']))]\n",
    "                idx = i\n",
    "\n",
    "        # Add the preprocessed sample to the dataset only if there is a label available\n",
    "        if label is not None:\n",
    "            X.append(torch.concat(embedded_sentence))\n",
    "            y.append(label)\n",
    "            index.append(idx)\n",
    "\n",
    "    y = torch.tensor(y).to(dtype=torch.float32)\n",
    "    index = torch.tensor(index).to(dtype=torch.int64)\n",
    "\n",
    "    return X, y, index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On n'a qu'à exécuter cette fonction sur les trois jeux de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, index_train = preprocess_dataset(train)\n",
    "X_val, y_val, index_val = preprocess_dataset(validation)\n",
    "X_test, y_test, index_test = preprocess_dataset(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 4\n",
    "\n",
    "Les tenseurs `y_train`, `y_val` et `y_test` sont des tenseurs binaires (chaque élément vaut $0$ ou $1$). Un $0$ correspond à un nom, tandis qu'un $1$ correspond à un verbe.\n",
    "Calculez la proportion de verbes sur les trois jeux pour avoir une idée de la précision (*accuracy*), c'est-à-dire la proportion de bonnes prédictions, d'un modèle trivial.\n",
    "Vous pouvez utiliser la méthode [mean()](https://pytorch.org/docs/stable/generated/torch.Tensor.mean.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unité récurrente fermée bidirectionnelle \n",
    "\n",
    "### Unité récurrente fermée\n",
    "\n",
    "L'**unité récurrente fermée** est un type de couche récurrente.\n",
    "Il s'agit d'une variante simplifiée de la *longue mémoire de court terme* :\n",
    "\n",
    "* Les **portes d'oubli et d'entrée** sont fusionnées en une seule **porte de mise à jour**.\n",
    "* La **cellule de mémoire** et l'**état caché** sont fusionnés en un seul **état caché**.\n",
    "\n",
    "L'image ci-dessous résume l'architecture de l'unité récurrente fermée :\n",
    "\n",
    "[<img src=\"https://raw.githubusercontent.com/johannfaouzi/apprentissage-profond-ensai/main/figures/gru_full.png\" width=\"500\"/>](https://raw.githubusercontent.com/johannfaouzi/apprentissage-profond-ensai/main/figures/gru_full.png)\n",
    "\n",
    "### Couche récurrente bidirectionnelle\n",
    "\n",
    "On souhaite classer un mot spécifique dans une phrase donnée, soit en nom soit en verbe.\n",
    "Pour effectuer cette tâche manuellement, un humain utiliserait la phrase en entier pour classer le mot.\n",
    "Si on utilise toute la séquence de tokens dans une couche récurrente classique, le modèle ne sait pas quel mot il doit classer dans la phrase.\n",
    "À l'inverse, si $k$ est l'indice du token à classer et si on n'utilise que les $k$ premiers tokens de la séquence, les tokens suivants ne sont pas utilisés.\n",
    "Pour résoudre ce problème, on va utiliser une couche récurrente **bidirectionnelle**.\n",
    "\n",
    "Une couche récurrente bidirectionnelle considère une séquence dans les deux sens :\n",
    "* le sens avant : $ x^{(0)} \\longrightarrow x^{(1)} \\longrightarrow \\ldots \\longrightarrow x^{(t-1)} \\longrightarrow x^{(t)} $\n",
    "* le sens arrière : $ x^{(0)} \\longleftarrow x^{(1)} \\longleftarrow \\ldots \\longleftarrow x^{(t-1)} \\longleftarrow x^{(t)} $\n",
    "\n",
    "L'image ci-dessous illustre ce principe :\n",
    "\n",
    "[<img src=\"https://raw.githubusercontent.com/johannfaouzi/apprentissage-profond-ensai/main/figures/rnn_bidir.png\" width=\"300\"/>](https://raw.githubusercontent.com/johannfaouzi/apprentissage-profond-ensai/main/figures/rnn_bidir.png)\n",
    "\n",
    "\n",
    "### Opération effectuée ici\n",
    "\n",
    "**Si $k$ est l'indice du token d'intérêt, on va extraire les tenseurs $\\overrightarrow{h}^{(k)}$ (l'état caché pour le token d'intérêt dans le sens avant) et $\\overleftarrow{h}^{(k)}$ (l'état caché pour le token d'intérêt dans le sens arrière)**.\n",
    "De cette manière, on indique au modèle quel mot on souhaite classer tout en utilisant tous les mots de la phrase.\n",
    "\n",
    "L'image ci-dessous illustre l'opération effectuée ici :\n",
    "\n",
    "[<img src=\"https://raw.githubusercontent.com/johannfaouzi/apprentissage-profond-ensai/main/figures/brnn_specific_token.png\" width=\"450\"/>](https://raw.githubusercontent.com/johannfaouzi/apprentissage-profond-ensai/main/figures/brnn_specific_token.png)\n",
    "\n",
    "\n",
    "### Quelques mots sur les séquences de longueur variable\n",
    "\n",
    "Une particularité des données textuelles est que la longueur des séquences n'est pas fixe : le nombre de mots dans une phrase varie d'une phrase à l'autre.\n",
    "Quand on travaille sur un lot de séquences, on ne peut pas créer directement un nouveau tenseur en dimension supérieure contenant toutes les séquences car les séquences peuvent être de longueur différente.\n",
    "\n",
    "Pour remédier à ce problème, une solution possible est de faire du **rembourrage** pour les séquences les plus courtes.\n",
    "Ainsi, les séquences (éventuellement rembourrées) sont toutes de la même longueur et on peut les traiter efficacement en lot.\n",
    "Cependant, ce n'est qu'une **astuce computationnelle** : on ne souhaite pas utiliser le rembourrage dans le traitement.\n",
    "Par conséquent, il faut également indiquer quelles valeurs ont été rembourrées pour ne pas les traiter.\n",
    "\n",
    "PyTorch fournit des outils pour implémenter cette solution :\n",
    "\n",
    "* [torch.nn.utils.rnn.pad_sequence()](https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_sequence.html) : cette fonction rembourre une liste de tenseurs de longueur variable.\n",
    "* [torch.nn.utils.rnn.pack_padded_sequence()](https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pack_padded_sequence.html) : cette fonction emballe un tenseur contenant des séquences de longueur variable rembourrées.\n",
    "* [torch.nn.utils.rnn.pad_packed_sequence()](https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_packed_sequence.html) : cette fonction rembourre un lot emballé de séquences de longueur variable (opération inverse de [pack_padded_sequence()](https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pack_padded_sequence.html)).\n",
    "\n",
    "Voici comment utiliser ces outils :\n",
    "\n",
    "1. Lorsque vous avez affaire à des séquences de longueur variable, l'entrée d'une couche récurrente doit être une instance de [PackedSequence](https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.PackedSequence.html). Pour obtenir une telle instance de cette classe, il faut d'abord rembourrer les séquences avec `pad_sequence()` puis emballer ces séquences avec `pack_padded_sequence()`.\n",
    "2. Lorsque l'entrée d'une couche récurrente est une instance de `PackedSequence`, sa sortie est également une instance de `PackedSequence`. Il suffit de déballer ces séquences avec `pad_packed_sequence()`.\n",
    "\n",
    "Voici une illustration de l'utilisation de ces outils :\n",
    "\n",
    "```python\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "sequence1 = torch.rand(6, 50)  # une séquence de longueur 6\n",
    "sequence2 = torch.rand(10, 50)  # une séquence de longueur 10\n",
    "sequence3 = torch.rand(9, 50)  # une séquence de longueur 9\n",
    "\n",
    "sequences = [sequence1, sequence2, sequence3]\n",
    "\n",
    "# On calcule la longueur des séquences\n",
    "lens = [sequence.size()[0] for sequence in sequences]\n",
    "\n",
    "# On rembourre cette liste de séquences\n",
    "sequences_padded = pad_sequence(sequences)\n",
    "\n",
    "# On emballe ces séquences éventuellement rembourrées\n",
    "sequences_packed = pack_padded_sequence(sequences_padded, lens, enforce_sorted=False)\n",
    "\n",
    "# On rembourre les séquences emballées\n",
    "sequences_unpacked, lens_unpacked = pad_packed_sequence(sequences_packed)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 5\n",
    "\n",
    "On va construire un réseau de neurones récurrent avec l'architecture suivante :\n",
    "\n",
    "* Première couche : couche GRU bidirectionnelle avec 100 variables cachées.\n",
    "* Deuxième couche : couche linéaire avec 1 variable en sortie.\n",
    "\n",
    "Quelques remarques importantes :\n",
    "\n",
    "* Comme on a un GRU bidirectionnel, l'état caché est un vecteur de taille $200 = 100 \\times 2$ car les deux tenseurs sont automatiquement concaténés.\n",
    "* On ne veut récupérer que l'état caché du token qui nous intéresse (c'est-à-dire du mot à classer).\n",
    "* Pour votre implémentation de la méthode `step()`, vous supposerez que le lot (l'argument `batch`) est une liste de tenseurs (on verra ensuite comment obtenir ce résultat).\n",
    "\n",
    "Complétez le code manquant dans les méthodes `__init__()` et `forward()` de la classe `RecurrentNeuralNetwork()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "\n",
    "class RecurrentNeuralNetwork(L.LightningModule):  # La classe hérite de la classe lightning.LightningModule\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Constructeur.\n",
    "\n",
    "        Dans le constructeur, on exécute le constructeur de la clase mère et on définit\n",
    "        toutes les couches et fonctions d'activation de notre réseau de neurones.\n",
    "        \"\"\"\n",
    "        super().__init__()  # Toujours exécuter le constructeur de la classe mère\n",
    "\n",
    "        ### BEGIN TODO ###\n",
    "        # self.gru =\n",
    "        # self.linear =\n",
    "        ### END TODO ###\n",
    "\n",
    "        self.loss = torch.nn.BCEWithLogitsLoss()\n",
    "        self.accuracy_train = Accuracy(task=\"binary\")\n",
    "        self.accuracy_val = Accuracy(task=\"binary\")\n",
    "        self.accuracy_test = Accuracy(task=\"binary\")\n",
    "\n",
    "    def forward(self, x, index):\n",
    "        \"\"\"Implémente la passe avant.\n",
    "\n",
    "        L'argument x est une liste de tenseurs correspondant soit à l'entrée une seule\n",
    "        observation soit aux entrées d'un lot d'observations.\n",
    "        \"\"\"\n",
    "        ### BEGIN TODO ###\n",
    "        # Calcule la longueur de chaque séquence\n",
    "\n",
    "        # Rembourre les séquences les plus petites\n",
    "\n",
    "        # Emballe les séquences rembourrées\n",
    "\n",
    "        # Applique la couche GRU\n",
    "\n",
    "        # Déballe la sortie de la couche GRU\n",
    "\n",
    "        # Récupère l'état caché pour chaque token d'intérêt\n",
    "\n",
    "        # Applique la couche linéaire\n",
    "        # y =\n",
    "        #### END TODO ####\n",
    "\n",
    "        return y\n",
    "\n",
    "    def step(self, batch, dataset):\n",
    "        \"\"\"Effectue une étape.\n",
    "\n",
    "        Une étape consiste à passer d'un lot d'observations (l'argument batch)\n",
    "        à l'évaluation de la fonction de coût pour ce lot d'observations.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch : tuple\n",
    "            Un lot d'observations. Le premier élément du tuple est le lot\n",
    "            des entrées, le second est le lot des labels.\n",
    "\n",
    "        dataset : {\"training\", \"validation\", \"test\"}\n",
    "            Jeu de données utilisé.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        loss : Tensor, shape = (1,)\n",
    "            La fonction de coût pour ce lot d'observations.\n",
    "        \"\"\"\n",
    "        # Récupère les données du lot d'observations\n",
    "        X = [item[0].to(self.device) for item in batch]\n",
    "        y = torch.tensor([item[1] for item in batch], device=self.device)\n",
    "        index = torch.tensor([item[2] for item in batch], device=self.device)\n",
    "\n",
    "        logits = self(X, index)  # Passe avant, qui renvoie les logits\n",
    "        loss = self.loss(logits, y)  # Évaluation de la fonction de coût\n",
    "        y_pred = (logits > 0).to(torch.float32)  # Prédictions du modèle\n",
    "\n",
    "        if dataset == \"training\":\n",
    "            metric = self.accuracy_train\n",
    "            name = \"train\"\n",
    "            bar_step = True\n",
    "        elif dataset == \"validation\":\n",
    "            metric = self.accuracy_val\n",
    "            name = \"val\"\n",
    "            bar_step = False\n",
    "        else:\n",
    "            metric = self.accuracy_test\n",
    "            name = \"test\"\n",
    "            bar_step = False\n",
    "\n",
    "        acc = metric(y_pred, y)  # Évaluation de la métrique\n",
    "        self.log(f\"loss_{name}\", loss, batch_size=len(y), prog_bar=bar_step, on_step=bar_step, on_epoch=True)\n",
    "        self.log(f\"accuracy_{name}\", acc, batch_size=len(y), prog_bar=bar_step, on_step=bar_step, on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        \"\"\"Effectue une étape d'entraînement.\"\"\"\n",
    "        return self.step(batch, \"training\")\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        \"\"\"Effectue une étape de validation.\"\"\"\n",
    "        return self.step(batch, \"validation\")\n",
    "\n",
    "    def test_step(self, batch):\n",
    "        \"\"\"Effectue une étape d'évaluation.\"\"\"\n",
    "        return self.step(batch, \"test\")\n",
    "\n",
    "    def on_train_start(self):\n",
    "        \"\"\"Code exécuté au début de l'entraînement.\"\"\"\n",
    "        string = f\"Version {self.trainer.logger.version}\"\n",
    "        print(f\"{string}\\n{'=' * len(string)}\\n\")\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        \"\"\"Code exécuté à la fin de chaque époque d'entraînement.\"\"\"\n",
    "        metrics = self.trainer.callback_metrics\n",
    "        string = (f\"\"\"\n",
    "            Époque {self.trainer.current_epoch + 1} / {self.trainer.max_epochs}\n",
    "            ------------------------------------------------\n",
    "            |     Jeu      | Fonction de perte | Précision |\n",
    "            | ------------ | ----------------- | --------- |\n",
    "            | Entraînement |{metrics['loss_train'].item():^19.5f}|{metrics['accuracy_train'].item():^11.3%}|\n",
    "            |  Validation  |{metrics['loss_val'].item():^19.5f}|{metrics['accuracy_val'].item():^11.3%}|\n",
    "            ------------------------------------------------\n",
    "        \"\"\")\n",
    "        string = '\\n'.join([line.strip() for line in string.split('\\n')])\n",
    "        print(string)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Configure l'algorithme d'optimisation à utiliser.\"\"\"\n",
    "        optimizer = torch.optim.Adam(self.parameters())\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quelques mots concernant le `DataLoader`\n",
    "\n",
    "On a vu qu'un [torch.utils.data.DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) permet de récupérer des lots d'observations de taille `batch_size`, avec un éventuel mélange des observations à chaque époque (si `shuffle=True`).\n",
    "Cependant, un `DataLoader` effectue bien plus de choses sous le capot.\n",
    "\n",
    "En particulier, avec les valeurs par défaut de certains hyperparamètres, il transforme une liste de tenseurs en un tenseur. Par exemple :\n",
    "\n",
    "* Si chaque entrée est un tenseur à 1 dimension de taille $50$ et si `batch_size=6`, alors la taille du tenseur renvoyé (correspondant au lot d'observations) est de taille $(6, 50)$.\n",
    "* Si chaque entrée est un tenseur à 2 dimensions de taille $(32, 32)$ et si `batch_size=4`, alors la taille du tenseur renvoyé (correspondant au lot d'observations) est de taille $(4, 32, 32)$.\n",
    "\n",
    "Le tenseur renvoyé a une dimension supplémentaire (la première dimension) correspondant aux observations.\n",
    "\n",
    "Comme on l'a vu dans la section précédente, une telle transformation est impossible avec des tenseurs de longueur différente.\n",
    "Par conséquent, il est nécessaire de désactiver cette transformation et d'implémenter notre propre transformation (avec le rembourrage et l'emballage).\n",
    "\n",
    "L'hyperparamètre de `DataLoader` qui contrôle cette transformation est `collate_fn` (voir la [documentation](https://pytorch.org/docs/stable/data.html#working-with-collate-fn) concerant cette hyperparamètre).\n",
    "Sa valeur doit être `None` ou un appelable (*callable*), donc en pratique une fonction.\n",
    "On peut désactiver la transformation en donnant la fonction identité comme argument pour cet hyperparamètre, soit `collate_fn=lambda x: x`.\n",
    "\n",
    "En effectuant ce changement, le `DataLoader` renverra maintenant une liste de longueur `batch_size`, chaque élément de cette liste étant ce qui est renvoyé par la méthode `__getitem__()` de l'instance de la classe personnalisée héritant de `Dataset`.\n",
    "\n",
    "> **Remarque** : Une autre possibilité aurait été d'effectuer les étapes de rembourrage et d'emballage dans la fonction `collate_fn`.\n",
    "\n",
    "### Exercice 6\n",
    "\n",
    "Créez votre propre classe `CustomDataset` héritant de la classe [torch.utils.data.Dataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset). Pour rappel, cette classe doit définir les trois méthodes suivantes :\n",
    "\n",
    "* `__len__()` : cette méthode renvoie le nombre d'observations du jeu de données.\n",
    "* `__getitem__()` : cette méthode charge et renvoie la n-ième observation du jeu de données (où n est un argument de la méthode)\n",
    "* `__init__()` : cette méthode définit toutes les informations nécessaires pour l'implémentation des deux autres méthodes.\n",
    "\n",
    "Créez ensuite un `Dataloader` pour chacun des trois jeux (entraînement, validation, évaluation) avec des lots de taille $64$ (`batch_size=64`).\n",
    "N'oubliez pas de mélanger les observations dans le jeu d'entraînement (`shuffle=True`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va maintenant entraîner notre modèle pendant 10 époques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks import TQDMProgressBar\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "\n",
    "\n",
    "model = RecurrentNeuralNetwork()\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=10,\n",
    "    enable_model_summary=False,  # supprimer le résumé du modèle\n",
    "    logger=CSVLogger('.'),  # sauvegarder les résultats dans un fichier CSV\n",
    "    num_sanity_val_steps=0,  # ne pas effectuer d'étape de validation avant l'entraînement\n",
    "    callbacks=[TQDMProgressBar(refresh_rate=10)]  # mettre à jour la barre de progression tous les 10 lots\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    model=model,\n",
    "    train_dataloaders=dataloader_train,\n",
    "    val_dataloaders=dataloader_val\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimisation des hyperparamètres\n",
    "\n",
    "La classe codée ci-dessus n'est pas très flexible, dans le sens où si on veut changer les valeurs de certains hyperparamètres alors on doit créer une nouvelle classe.\n",
    "Il vaut mieux avoir une classe flexible, avec des arguments en entrée permettant de changer les valeurs de ces hyperparamètres à la création d'une instance de cette classe.\n",
    "\n",
    "La classe `RecurrentNeuralNetworkAdvanced` définie ci-dessous permet de personnaliser un peu l'architecture du modèle.\n",
    "On a toujours un réseau de neurones récurrent avec une ou plusieurs couches récurrentes suivies d'une ou plusieurs couches linéaires.\n",
    "Néanmoins, les modifications suivantes sont possibles grâce aux arguments de la classe :\n",
    "\n",
    "* On peut choisir le type de couche récurrente (RNN / LSTM / GRU).\n",
    "* On peut choisir le nombre de couches récurrentes.\n",
    "* On peut choisir le nombre de variables dans l'état caché des couches récurrentes.\n",
    "* On peut choisir le nombre de couches linéaires ainsi que leurs tailles.\n",
    "* On peut choisir la fonction d'activation à utiliser entre les couches linéaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "\n",
    "class RecurrentNeuralNetworkAdvanced(L.LightningModule):\n",
    "    \"\"\"Classe générale pour un réseau de neurones récurrent.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    rnn_type : {'rnn', 'lstm', 'gru'}\n",
    "        Type de couche récurrente.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        rnn_type='gru',\n",
    "        n_rnn=1,\n",
    "        hidden_size_rnn=100,\n",
    "        n_linear=1,\n",
    "        output_size_linear=100,\n",
    "        activation=torch.nn.ReLU()\n",
    "    ):\n",
    "        \"\"\"Constructeur.\n",
    "\n",
    "        Dans le constructeur, on exécute le constructeur de la clase mère et on définit\n",
    "        toutes les couches et fonctions d'activation de notre réseau de neurones.\n",
    "        \"\"\"\n",
    "        super().__init__()  # Toujours exécuter le constructeur de la classe mère\n",
    "\n",
    "        # Couches récurrentes\n",
    "        if rnn_type == 'rnn':\n",
    "            self.rnn = torch.nn.RNN(\n",
    "                50, hidden_size=hidden_size_rnn, num_layers=n_rnn, bidirectional=True\n",
    "            )\n",
    "        elif rnn_type == 'lstm':\n",
    "            self.rnn = torch.nn.LSTM(\n",
    "                50, hidden_size=hidden_size_rnn, num_layers=n_rnn, bidirectional=True\n",
    "            )\n",
    "        elif rnn_type == 'gru':\n",
    "            self.rnn = torch.nn.GRU(\n",
    "                50, hidden_size=hidden_size_rnn, num_layers=n_rnn, bidirectional=True\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"rnn must be one of 'rnn', 'lstm' or 'gru'.\")\n",
    "\n",
    "        # Couches linéaires\n",
    "        size_linear = [2 * hidden_size_rnn]\n",
    "\n",
    "        if isinstance(output_size_linear, int):\n",
    "            size_linear += [output_size_linear] * (n_linear - 1)\n",
    "        else:\n",
    "            size_linear += list(output_size_linear)\n",
    "        size_linear += [1]\n",
    "\n",
    "        self.linear = torch.nn.Sequential(\n",
    "            *(\n",
    "                [torch.nn.Sequential(torch.nn.Linear(in_features, out_features), activation)\n",
    "                 for in_features, out_features in zip(size_linear[:-2], size_linear[1:-1])]\n",
    "                + [torch.nn.Linear(size_linear[-2], size_linear[-1])]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.loss = torch.nn.BCEWithLogitsLoss()\n",
    "        self.accuracy_train = Accuracy(task=\"binary\")\n",
    "        self.accuracy_val = Accuracy(task=\"binary\")\n",
    "        self.accuracy_test = Accuracy(task=\"binary\")\n",
    "\n",
    "    def forward(self, x, index):\n",
    "        \"\"\"Implémente la passe avant.\n",
    "\n",
    "        L'argument x est une liste de tenseurs correspondant soit à l'entrée une seule\n",
    "        observation soit aux entrées d'un lot d'observations.\n",
    "        \"\"\"\n",
    "        # Calcule la longueur de chaque séquence\n",
    "        lens = [sequence.size()[0] for sequence in x]\n",
    "\n",
    "        # Rembourre les séquences les plus petites\n",
    "        x_padded = pad_sequence(x)\n",
    "\n",
    "        # Emballe les séquences rembourrées\n",
    "        x_packed = pack_padded_sequence(x_padded, lens, enforce_sorted=False)\n",
    "\n",
    "        # Applique la couche GRU\n",
    "        output_packed, _ = self.rnn(x_packed)\n",
    "\n",
    "        # Déballe la sortie de la couche GRU\n",
    "        output_unpacked, _ = pad_packed_sequence(output_packed)\n",
    "\n",
    "        # Récupère l'état caché pour chaque token d'intérêt\n",
    "        h = torch.concat([output_unpacked[idx, i].reshape(1, -1) for i, idx in enumerate(index)])\n",
    "\n",
    "        # Applique la couche linéaire\n",
    "        y = torch.squeeze(self.linear(h))\n",
    "\n",
    "        return y\n",
    "\n",
    "    def step(self, batch, dataset):\n",
    "        \"\"\"Effectue une étape.\n",
    "\n",
    "        Une étape consiste à passer d'un lot d'observations (l'argument batch)\n",
    "        à l'évaluation de la fonction de coût pour ce lot d'observations.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch : tuple\n",
    "            Un lot d'observations. Le premier élément du tuple est le lot\n",
    "            des entrées, le second est le lot des labels.\n",
    "\n",
    "        dataset : {\"training\", \"validation\", \"test\"}\n",
    "            Jeu de données utilisé.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        loss : Tensor, shape = (1,)\n",
    "            La fonction de coût pour ce lot d'observations.\n",
    "        \"\"\"\n",
    "        # Récupère les données du lot d'observations\n",
    "        X = [item[0].to(self.device) for item in batch]\n",
    "        y = torch.tensor([item[1] for item in batch], device=self.device)\n",
    "        index = torch.tensor([item[2] for item in batch], device=self.device)\n",
    "\n",
    "        logits = self(X, index)  # Passe avant, qui renvoie les logits\n",
    "        loss = self.loss(logits, y)  # Évaluation de la fonction de coût\n",
    "        y_pred = (logits > 0).to(torch.float32)  # Prédictions du modèle\n",
    "\n",
    "        if dataset == \"training\":\n",
    "            metric = self.accuracy_train\n",
    "            name = \"train\"\n",
    "            bar_step = True\n",
    "        elif dataset == \"validation\":\n",
    "            metric = self.accuracy_val\n",
    "            name = \"val\"\n",
    "            bar_step = False\n",
    "        else:\n",
    "            metric = self.accuracy_test\n",
    "            name = \"test\"\n",
    "            bar_step = False\n",
    "\n",
    "        acc = metric(y_pred, y)  # Évaluation de la métrique\n",
    "        self.log(f\"loss_{name}\", loss, batch_size=len(y), prog_bar=bar_step, on_step=bar_step, on_epoch=True)\n",
    "        self.log(f\"accuracy_{name}\", acc, batch_size=len(y), prog_bar=bar_step, on_step=bar_step, on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        \"\"\"Effectue une étape d'entraînement.\"\"\"\n",
    "        return self.step(batch, \"training\")\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        \"\"\"Effectue une étape de validation.\"\"\"\n",
    "        return self.step(batch, \"validation\")\n",
    "\n",
    "    def test_step(self, batch):\n",
    "        \"\"\"Effectue une étape d'évaluation.\"\"\"\n",
    "        return self.step(batch, \"test\")\n",
    "\n",
    "    def on_train_start(self):\n",
    "        \"\"\"Code exécuté au début de l'entraînement.\"\"\"\n",
    "        string = f\"Version {self.trainer.logger.version}\"\n",
    "        print(f\"{string}\\n{'=' * len(string)}\\n\")\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        \"\"\"Code exécuté à la fin de chaque époque d'entraînement.\"\"\"\n",
    "        metrics = self.trainer.callback_metrics\n",
    "        string = (f\"\"\"\n",
    "            Époque {self.trainer.current_epoch + 1} / {self.trainer.max_epochs}\n",
    "            -----------------------------------------------\n",
    "            |     Jeu      | Fonction de coût | Précision |\n",
    "            | ------------ | ---------------- | --------- |\n",
    "            | Entraînement |{metrics['loss_train'].item():^18.6f}|{metrics['accuracy_train'].item():^11.3%}|\n",
    "            |  Validation  |{metrics['loss_val'].item():^18.6f}|{metrics['accuracy_val'].item():^11.3%}|\n",
    "            -----------------------------------------------\n",
    "        \"\"\")\n",
    "        string = '\\n'.join([line.strip() for line in string.split('\\n')])\n",
    "        print(string)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Configure l'algorithme d'optimisation à utiliser.\"\"\"\n",
    "        optimizer = torch.optim.Adam(self.parameters())\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 7\n",
    "\n",
    "Initialisez quelques modèles avec des combinaisons différentes pour les valeurs de ces hyperparamètres.\n",
    "N'entraînez pas les modèles, mais effectuez une passe avant sur un petit lot d'observations pour vous assurer qu'aucune erreur n'est levée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 8\n",
    "\n",
    "Utilisez votre nouvelle classe personnalisée pour initialiser un modèle avec une architecture différente du premier modèle.\n",
    "**N'oubliez pas que plus votre modèle est profond et a de paramètres entraînables, plus l'entraînement prendra du temps.**\n",
    "Si vous avez assez de temps, essayez plusieurs architectures.\n",
    "Dans tous les cas, sauvegardez tous vos modèles !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 9\n",
    "\n",
    "En théorie, il faudrait choisir le meilleur modèle sur le jeu de validation et l'évaluer sur le jeu d'évaluation. Par curiosité, on va ici évaluer tous les modèles sur le jeu d'évaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
